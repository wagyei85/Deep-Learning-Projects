{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout,Flatten,Conv2D,MaxPool2D\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df.label\n",
    "x=df.drop('label',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=x/255.0\n",
    "x=x.values.reshape(-1,28,28,1)\n",
    "y=np.array(y)\n",
    "y=to_categorical(y,num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((42000, 28, 28, 1), (42000, 10))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.20,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'> <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(xtrain),type(xtest),type(ytrain),type(ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x16cf29af148>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow((xtrain[0][:,:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    # The first two layers with 32 filters of window size 3x3\n",
    "    model.add(Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=(28, 28, 1)))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "    model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 33600 samples, validate on 8400 samples\n",
      "Epoch 1/500\n",
      "33600/33600 [==============================] - 110s 3ms/step - loss: 0.8162 - accuracy: 0.7293 - val_loss: 0.2304 - val_accuracy: 0.9231\n",
      "Epoch 2/500\n",
      "33600/33600 [==============================] - 117s 3ms/step - loss: 0.1914 - accuracy: 0.9435 - val_loss: 0.0912 - val_accuracy: 0.9725\n",
      "Epoch 3/500\n",
      "33600/33600 [==============================] - 115s 3ms/step - loss: 0.1181 - accuracy: 0.9655 - val_loss: 0.0605 - val_accuracy: 0.9812\n",
      "Epoch 4/500\n",
      "33600/33600 [==============================] - 112s 3ms/step - loss: 0.0875 - accuracy: 0.9755 - val_loss: 0.0712 - val_accuracy: 0.9788\n",
      "Epoch 5/500\n",
      "33600/33600 [==============================] - 100s 3ms/step - loss: 0.0716 - accuracy: 0.9800 - val_loss: 0.0515 - val_accuracy: 0.9860\n",
      "Epoch 6/500\n",
      "33600/33600 [==============================] - 103s 3ms/step - loss: 0.0626 - accuracy: 0.9823 - val_loss: 0.0458 - val_accuracy: 0.9869\n",
      "Epoch 7/500\n",
      "33600/33600 [==============================] - 103s 3ms/step - loss: 0.0526 - accuracy: 0.9846 - val_loss: 0.0371 - val_accuracy: 0.9887\n",
      "Epoch 8/500\n",
      "33600/33600 [==============================] - 102s 3ms/step - loss: 0.0491 - accuracy: 0.9860 - val_loss: 0.0352 - val_accuracy: 0.9892\n",
      "Epoch 9/500\n",
      "33600/33600 [==============================] - 100s 3ms/step - loss: 0.0444 - accuracy: 0.9871 - val_loss: 0.0379 - val_accuracy: 0.9892\n",
      "Epoch 10/500\n",
      "33600/33600 [==============================] - 99s 3ms/step - loss: 0.0374 - accuracy: 0.9894 - val_loss: 0.0346 - val_accuracy: 0.9899\n",
      "Epoch 11/500\n",
      "33600/33600 [==============================] - 101s 3ms/step - loss: 0.0343 - accuracy: 0.9902 - val_loss: 0.0314 - val_accuracy: 0.9913\n",
      "Epoch 12/500\n",
      "33600/33600 [==============================] - 100s 3ms/step - loss: 0.0333 - accuracy: 0.9911 - val_loss: 0.0320 - val_accuracy: 0.9907\n",
      "Epoch 13/500\n",
      "33600/33600 [==============================] - 99s 3ms/step - loss: 0.0313 - accuracy: 0.9908 - val_loss: 0.0265 - val_accuracy: 0.9920\n",
      "Epoch 14/500\n",
      "33600/33600 [==============================] - 100s 3ms/step - loss: 0.0262 - accuracy: 0.9924 - val_loss: 0.0254 - val_accuracy: 0.9926\n",
      "Epoch 15/500\n",
      "33600/33600 [==============================] - 100s 3ms/step - loss: 0.0291 - accuracy: 0.9916 - val_loss: 0.0329 - val_accuracy: 0.9911\n",
      "Epoch 16/500\n",
      "33600/33600 [==============================] - 99s 3ms/step - loss: 0.0249 - accuracy: 0.9927 - val_loss: 0.0228 - val_accuracy: 0.9929\n",
      "Epoch 17/500\n",
      "33600/33600 [==============================] - 100s 3ms/step - loss: 0.0225 - accuracy: 0.9938 - val_loss: 0.0263 - val_accuracy: 0.9920\n",
      "Epoch 18/500\n",
      "33600/33600 [==============================] - 100s 3ms/step - loss: 0.0233 - accuracy: 0.9930 - val_loss: 0.0308 - val_accuracy: 0.9925\n",
      "Epoch 19/500\n",
      "33600/33600 [==============================] - 99s 3ms/step - loss: 0.0213 - accuracy: 0.9938 - val_loss: 0.0289 - val_accuracy: 0.9924\n",
      "Epoch 20/500\n",
      "33600/33600 [==============================] - 100s 3ms/step - loss: 0.0210 - accuracy: 0.9938 - val_loss: 0.0343 - val_accuracy: 0.9908\n",
      "Epoch 21/500\n",
      "33600/33600 [==============================] - 100s 3ms/step - loss: 0.0202 - accuracy: 0.9943 - val_loss: 0.0244 - val_accuracy: 0.9926\n",
      "Epoch 22/500\n",
      "33600/33600 [==============================] - 99s 3ms/step - loss: 0.0183 - accuracy: 0.9945 - val_loss: 0.0336 - val_accuracy: 0.9933\n",
      "Epoch 23/500\n",
      "33600/33600 [==============================] - 99s 3ms/step - loss: 0.0185 - accuracy: 0.9947 - val_loss: 0.0241 - val_accuracy: 0.9935\n",
      "Epoch 24/500\n",
      "33600/33600 [==============================] - 99s 3ms/step - loss: 0.0178 - accuracy: 0.9952 - val_loss: 0.0235 - val_accuracy: 0.9939\n",
      "Epoch 25/500\n",
      "33600/33600 [==============================] - 100s 3ms/step - loss: 0.0159 - accuracy: 0.9955 - val_loss: 0.0303 - val_accuracy: 0.9929\n",
      "Epoch 26/500\n",
      "33600/33600 [==============================] - 100s 3ms/step - loss: 0.0163 - accuracy: 0.9954 - val_loss: 0.0271 - val_accuracy: 0.9938\n",
      "Epoch 27/500\n",
      "33600/33600 [==============================] - 100s 3ms/step - loss: 0.0159 - accuracy: 0.9958 - val_loss: 0.0245 - val_accuracy: 0.9943\n",
      "Epoch 28/500\n",
      "33600/33600 [==============================] - 100s 3ms/step - loss: 0.0148 - accuracy: 0.9957 - val_loss: 0.0375 - val_accuracy: 0.9927\n",
      "Epoch 29/500\n",
      "33600/33600 [==============================] - 100s 3ms/step - loss: 0.0147 - accuracy: 0.9961 - val_loss: 0.0240 - val_accuracy: 0.9949\n",
      "Epoch 30/500\n",
      "33600/33600 [==============================] - 99s 3ms/step - loss: 0.0141 - accuracy: 0.9965 - val_loss: 0.0290 - val_accuracy: 0.9933\n",
      "Epoch 31/500\n",
      "33600/33600 [==============================] - 100s 3ms/step - loss: 0.0139 - accuracy: 0.9962 - val_loss: 0.0358 - val_accuracy: 0.9930\n",
      "Epoch 32/500\n",
      "33600/33600 [==============================] - 100s 3ms/step - loss: 0.0146 - accuracy: 0.9962 - val_loss: 0.0349 - val_accuracy: 0.9929\n",
      "Epoch 33/500\n",
      "33600/33600 [==============================] - 100s 3ms/step - loss: 0.0149 - accuracy: 0.9959 - val_loss: 0.0333 - val_accuracy: 0.9933\n",
      "Epoch 34/500\n",
      "33600/33600 [==============================] - 100s 3ms/step - loss: 0.0160 - accuracy: 0.9959 - val_loss: 0.0335 - val_accuracy: 0.9921\n",
      "Epoch 35/500\n",
      "33600/33600 [==============================] - 99s 3ms/step - loss: 0.0140 - accuracy: 0.9962 - val_loss: 0.0280 - val_accuracy: 0.9940\n",
      "Epoch 36/500\n",
      "33600/33600 [==============================] - 99s 3ms/step - loss: 0.0131 - accuracy: 0.9964 - val_loss: 0.0507 - val_accuracy: 0.9882\n",
      "Epoch 37/500\n",
      "33600/33600 [==============================] - 100s 3ms/step - loss: 0.0152 - accuracy: 0.9959 - val_loss: 0.0272 - val_accuracy: 0.9945\n",
      "Epoch 38/500\n",
      "33600/33600 [==============================] - 101s 3ms/step - loss: 0.0139 - accuracy: 0.9967 - val_loss: 0.0267 - val_accuracy: 0.9940\n",
      "Epoch 39/500\n",
      "33600/33600 [==============================] - 100s 3ms/step - loss: 0.0160 - accuracy: 0.9957 - val_loss: 0.0345 - val_accuracy: 0.9926\n",
      "Epoch 40/500\n",
      "33600/33600 [==============================] - 100s 3ms/step - loss: 0.0144 - accuracy: 0.9961 - val_loss: 0.0419 - val_accuracy: 0.9932\n",
      "Epoch 41/500\n",
      "33600/33600 [==============================] - 100s 3ms/step - loss: 0.0147 - accuracy: 0.9968 - val_loss: 0.0333 - val_accuracy: 0.9931\n",
      "Epoch 42/500\n",
      "33600/33600 [==============================] - 100s 3ms/step - loss: 0.0116 - accuracy: 0.9969 - val_loss: 0.0375 - val_accuracy: 0.9939\n",
      "Epoch 43/500\n",
      "33600/33600 [==============================] - 103s 3ms/step - loss: 0.0115 - accuracy: 0.9968 - val_loss: 0.0365 - val_accuracy: 0.9938\n",
      "Epoch 44/500\n",
      "33600/33600 [==============================] - 101s 3ms/step - loss: 0.0132 - accuracy: 0.9964 - val_loss: 0.0353 - val_accuracy: 0.9921\n",
      "Epoch 45/500\n",
      "33600/33600 [==============================] - 100s 3ms/step - loss: 0.0137 - accuracy: 0.9966 - val_loss: 0.0377 - val_accuracy: 0.9939\n",
      "Epoch 46/500\n",
      "33600/33600 [==============================] - 100s 3ms/step - loss: 0.0143 - accuracy: 0.9968 - val_loss: 0.0469 - val_accuracy: 0.9911\n",
      "Epoch 47/500\n",
      "33600/33600 [==============================] - 100s 3ms/step - loss: 0.0128 - accuracy: 0.9968 - val_loss: 0.0279 - val_accuracy: 0.9940\n",
      "Epoch 48/500\n",
      "33600/33600 [==============================] - 101s 3ms/step - loss: 0.0149 - accuracy: 0.9964 - val_loss: 0.0358 - val_accuracy: 0.9936\n",
      "Epoch 49/500\n",
      "33600/33600 [==============================] - 100s 3ms/step - loss: 0.0124 - accuracy: 0.9968 - val_loss: 0.0341 - val_accuracy: 0.9942\n",
      "Epoch 50/500\n",
      "33600/33600 [==============================] - 100s 3ms/step - loss: 0.0128 - accuracy: 0.9966 - val_loss: 0.0317 - val_accuracy: 0.9940\n",
      "Epoch 51/500\n",
      "33600/33600 [==============================] - 100s 3ms/step - loss: 0.0138 - accuracy: 0.9968 - val_loss: 0.0367 - val_accuracy: 0.9930\n",
      "Epoch 52/500\n",
      "33600/33600 [==============================] - 100s 3ms/step - loss: 0.0126 - accuracy: 0.9968 - val_loss: 0.0399 - val_accuracy: 0.9936\n",
      "Epoch 53/500\n",
      "33600/33600 [==============================] - 101s 3ms/step - loss: 0.0122 - accuracy: 0.9967 - val_loss: 0.0422 - val_accuracy: 0.9932\n",
      "Epoch 54/500\n",
      "33600/33600 [==============================] - 100s 3ms/step - loss: 0.0128 - accuracy: 0.9968 - val_loss: 0.0429 - val_accuracy: 0.9924\n",
      "Epoch 55/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33600/33600 [==============================] - 101s 3ms/step - loss: 0.0131 - accuracy: 0.9968 - val_loss: 0.0445 - val_accuracy: 0.9937\n",
      "Epoch 56/500\n",
      "33600/33600 [==============================] - 101s 3ms/step - loss: 0.0120 - accuracy: 0.9970 - val_loss: 0.0335 - val_accuracy: 0.9939\n",
      "Epoch 57/500\n",
      "33600/33600 [==============================] - 100s 3ms/step - loss: 0.0110 - accuracy: 0.9968 - val_loss: 0.0419 - val_accuracy: 0.9935\n",
      "Epoch 58/500\n",
      "33600/33600 [==============================] - 101s 3ms/step - loss: 0.0114 - accuracy: 0.9971 - val_loss: 0.0345 - val_accuracy: 0.9939\n",
      "Epoch 59/500\n",
      "33600/33600 [==============================] - 100s 3ms/step - loss: 0.0131 - accuracy: 0.9969 - val_loss: 0.0623 - val_accuracy: 0.9890\n",
      "Epoch 60/500\n",
      "33600/33600 [==============================] - 99s 3ms/step - loss: 0.0136 - accuracy: 0.9970 - val_loss: 0.0512 - val_accuracy: 0.9932\n",
      "Epoch 61/500\n",
      "33600/33600 [==============================] - 100s 3ms/step - loss: 0.0142 - accuracy: 0.9971 - val_loss: 0.0433 - val_accuracy: 0.9932\n",
      "Epoch 62/500\n",
      "33600/33600 [==============================] - 100s 3ms/step - loss: 0.0141 - accuracy: 0.9967 - val_loss: 0.0344 - val_accuracy: 0.9944\n",
      "Epoch 63/500\n",
      "33600/33600 [==============================] - 100s 3ms/step - loss: 0.0158 - accuracy: 0.9965 - val_loss: 0.0394 - val_accuracy: 0.9933\n",
      "Epoch 64/500\n",
      "33600/33600 [==============================] - 100s 3ms/step - loss: 0.0121 - accuracy: 0.9969 - val_loss: 0.0511 - val_accuracy: 0.9945\n",
      "Epoch 65/500\n",
      "33600/33600 [==============================] - 100s 3ms/step - loss: 0.0137 - accuracy: 0.9969 - val_loss: 0.0458 - val_accuracy: 0.9937\n",
      "Epoch 66/500\n",
      "33600/33600 [==============================] - 100s 3ms/step - loss: 0.0148 - accuracy: 0.9965 - val_loss: 0.0366 - val_accuracy: 0.9938\n",
      "Epoch 67/500\n",
      "33600/33600 [==============================] - 99s 3ms/step - loss: 0.0111 - accuracy: 0.9973 - val_loss: 0.0428 - val_accuracy: 0.9931\n",
      "Epoch 68/500\n",
      "33600/33600 [==============================] - 101s 3ms/step - loss: 0.0137 - accuracy: 0.9967 - val_loss: 0.0462 - val_accuracy: 0.9940\n",
      "Epoch 69/500\n",
      "33600/33600 [==============================] - 101s 3ms/step - loss: 0.0145 - accuracy: 0.9967 - val_loss: 0.0452 - val_accuracy: 0.9931\n",
      "Epoch 70/500\n",
      "33600/33600 [==============================] - 100s 3ms/step - loss: 0.0141 - accuracy: 0.9963 - val_loss: 0.0486 - val_accuracy: 0.9920\n",
      "Epoch 71/500\n",
      "33600/33600 [==============================] - 100s 3ms/step - loss: 0.0156 - accuracy: 0.9965 - val_loss: 0.0582 - val_accuracy: 0.9930\n",
      "Epoch 72/500\n",
      "33600/33600 [==============================] - 99s 3ms/step - loss: 0.0145 - accuracy: 0.9968 - val_loss: 0.0363 - val_accuracy: 0.9925\n",
      "Epoch 73/500\n",
      "33600/33600 [==============================] - 99s 3ms/step - loss: 0.0137 - accuracy: 0.9969 - val_loss: 0.0428 - val_accuracy: 0.9938\n",
      "Epoch 74/500\n",
      "33600/33600 [==============================] - 101s 3ms/step - loss: 0.0171 - accuracy: 0.9963 - val_loss: 0.0533 - val_accuracy: 0.9936\n",
      "Epoch 75/500\n",
      "33600/33600 [==============================] - 100s 3ms/step - loss: 0.0150 - accuracy: 0.9965 - val_loss: 0.0404 - val_accuracy: 0.9932\n",
      "Epoch 76/500\n",
      "33600/33600 [==============================] - 100s 3ms/step - loss: 0.0151 - accuracy: 0.9967 - val_loss: 0.0553 - val_accuracy: 0.9939\n",
      "Epoch 77/500\n",
      "33600/33600 [==============================] - 100s 3ms/step - loss: 0.0127 - accuracy: 0.9972 - val_loss: 0.0406 - val_accuracy: 0.9935\n",
      "Epoch 78/500\n",
      "33600/33600 [==============================] - 100s 3ms/step - loss: 0.0149 - accuracy: 0.9971 - val_loss: 0.0410 - val_accuracy: 0.9917\n",
      "Epoch 79/500\n",
      "33600/33600 [==============================] - 101s 3ms/step - loss: 0.0146 - accuracy: 0.9968 - val_loss: 0.0557 - val_accuracy: 0.9931\n",
      "Epoch 80/500\n",
      "33600/33600 [==============================] - 101s 3ms/step - loss: 0.0143 - accuracy: 0.9971 - val_loss: 0.0649 - val_accuracy: 0.9938\n",
      "Epoch 81/500\n",
      "33600/33600 [==============================] - 100s 3ms/step - loss: 0.0147 - accuracy: 0.9973 - val_loss: 0.0649 - val_accuracy: 0.9938\n",
      "Epoch 82/500\n",
      "33600/33600 [==============================] - 101s 3ms/step - loss: 0.0144 - accuracy: 0.9968 - val_loss: 0.0623 - val_accuracy: 0.9925\n",
      "Epoch 83/500\n",
      "33600/33600 [==============================] - 100s 3ms/step - loss: 0.0178 - accuracy: 0.9959 - val_loss: 0.0491 - val_accuracy: 0.9918\n",
      "Epoch 84/500\n",
      "33600/33600 [==============================] - 100s 3ms/step - loss: 0.0166 - accuracy: 0.9964 - val_loss: 0.0618 - val_accuracy: 0.9929\n",
      "Epoch 85/500\n",
      "33600/33600 [==============================] - 99s 3ms/step - loss: 0.0169 - accuracy: 0.9965 - val_loss: 0.0529 - val_accuracy: 0.9929\n",
      "Epoch 86/500\n",
      "33600/33600 [==============================] - 101s 3ms/step - loss: 0.0153 - accuracy: 0.9967 - val_loss: 0.0495 - val_accuracy: 0.9937\n",
      "Epoch 87/500\n",
      "33600/33600 [==============================] - 100s 3ms/step - loss: 0.0179 - accuracy: 0.9961 - val_loss: 0.0617 - val_accuracy: 0.9938\n",
      "Epoch 88/500\n",
      "33600/33600 [==============================] - 100s 3ms/step - loss: 0.0173 - accuracy: 0.9965 - val_loss: 0.0469 - val_accuracy: 0.9936\n",
      "Epoch 89/500\n",
      "33600/33600 [==============================] - 101s 3ms/step - loss: 0.0153 - accuracy: 0.9962 - val_loss: 0.0393 - val_accuracy: 0.9943\n",
      "Epoch 90/500\n",
      "33600/33600 [==============================] - 99s 3ms/step - loss: 0.0170 - accuracy: 0.9963 - val_loss: 0.0401 - val_accuracy: 0.9912\n",
      "Epoch 91/500\n",
      "33600/33600 [==============================] - 100s 3ms/step - loss: 0.0165 - accuracy: 0.9966 - val_loss: 0.0401 - val_accuracy: 0.9936\n",
      "Epoch 92/500\n",
      "33600/33600 [==============================] - 101s 3ms/step - loss: 0.0185 - accuracy: 0.9958 - val_loss: 0.0694 - val_accuracy: 0.9937\n",
      "Epoch 93/500\n",
      "33600/33600 [==============================] - 101s 3ms/step - loss: 0.0185 - accuracy: 0.9965 - val_loss: 0.0444 - val_accuracy: 0.9930\n",
      "Epoch 94/500\n",
      "33600/33600 [==============================] - 101s 3ms/step - loss: 0.0172 - accuracy: 0.9964 - val_loss: 0.0348 - val_accuracy: 0.9935\n",
      "Epoch 95/500\n",
      "33600/33600 [==============================] - 100s 3ms/step - loss: 0.0152 - accuracy: 0.9968 - val_loss: 0.0386 - val_accuracy: 0.9913\n",
      "Epoch 96/500\n",
      "33600/33600 [==============================] - 101s 3ms/step - loss: 0.0139 - accuracy: 0.9964 - val_loss: 0.0387 - val_accuracy: 0.9935\n",
      "Epoch 97/500\n",
      "33600/33600 [==============================] - 101s 3ms/step - loss: 0.0155 - accuracy: 0.9962 - val_loss: 0.0429 - val_accuracy: 0.9936\n",
      "Epoch 98/500\n",
      "33600/33600 [==============================] - 100s 3ms/step - loss: 0.0182 - accuracy: 0.9967 - val_loss: 0.0555 - val_accuracy: 0.9925\n",
      "Epoch 99/500\n",
      "33600/33600 [==============================] - 100s 3ms/step - loss: 0.0168 - accuracy: 0.9965 - val_loss: 0.0314 - val_accuracy: 0.9935\n",
      "Epoch 100/500\n",
      "33600/33600 [==============================] - 100s 3ms/step - loss: 0.0155 - accuracy: 0.9964 - val_loss: 0.0640 - val_accuracy: 0.9939\n",
      "Epoch 101/500\n",
      "33600/33600 [==============================] - 100s 3ms/step - loss: 0.0157 - accuracy: 0.9965 - val_loss: 0.0447 - val_accuracy: 0.9925\n",
      "Epoch 102/500\n",
      "33600/33600 [==============================] - 100s 3ms/step - loss: 0.0152 - accuracy: 0.9963 - val_loss: 0.0479 - val_accuracy: 0.9937\n",
      "Epoch 103/500\n",
      "33600/33600 [==============================] - 100s 3ms/step - loss: 0.0192 - accuracy: 0.9960 - val_loss: 0.0446 - val_accuracy: 0.9925\n",
      "Epoch 104/500\n",
      "33600/33600 [==============================] - 101s 3ms/step - loss: 0.0188 - accuracy: 0.9958 - val_loss: 0.0466 - val_accuracy: 0.9938\n",
      "Epoch 105/500\n",
      "33600/33600 [==============================] - 100s 3ms/step - loss: 0.0182 - accuracy: 0.9960 - val_loss: 0.0357 - val_accuracy: 0.9931\n",
      "Epoch 106/500\n",
      "33600/33600 [==============================] - 100s 3ms/step - loss: 0.0193 - accuracy: 0.9962 - val_loss: 0.0723 - val_accuracy: 0.9910\n",
      "Epoch 107/500\n",
      "33600/33600 [==============================] - 100s 3ms/step - loss: 0.0164 - accuracy: 0.9965 - val_loss: 0.0440 - val_accuracy: 0.9931\n",
      "Epoch 108/500\n",
      "33600/33600 [==============================] - 100s 3ms/step - loss: 0.0210 - accuracy: 0.9956 - val_loss: 0.0641 - val_accuracy: 0.9904\n",
      "Epoch 109/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33600/33600 [==============================] - 100s 3ms/step - loss: 0.0180 - accuracy: 0.9963 - val_loss: 0.0480 - val_accuracy: 0.9931\n",
      "Epoch 110/500\n",
      "33600/33600 [==============================] - 101s 3ms/step - loss: 0.0204 - accuracy: 0.9961 - val_loss: 0.0357 - val_accuracy: 0.9943\n",
      "Epoch 111/500\n",
      "33600/33600 [==============================] - 101s 3ms/step - loss: 0.0187 - accuracy: 0.9963 - val_loss: 0.0601 - val_accuracy: 0.9939\n",
      "Epoch 112/500\n",
      "33600/33600 [==============================] - 100s 3ms/step - loss: 0.0199 - accuracy: 0.9957 - val_loss: 0.0489 - val_accuracy: 0.9931\n",
      "Epoch 113/500\n",
      "33600/33600 [==============================] - 100s 3ms/step - loss: 0.0184 - accuracy: 0.9968 - val_loss: 0.0697 - val_accuracy: 0.9923\n",
      "Epoch 114/500\n",
      "33600/33600 [==============================] - 100s 3ms/step - loss: 0.0148 - accuracy: 0.9967 - val_loss: 0.0413 - val_accuracy: 0.9939\n",
      "Epoch 115/500\n",
      "33600/33600 [==============================] - 104s 3ms/step - loss: 0.0205 - accuracy: 0.9961 - val_loss: 0.0595 - val_accuracy: 0.9942\n",
      "Epoch 116/500\n",
      "33600/33600 [==============================] - 101s 3ms/step - loss: 0.0127 - accuracy: 0.9974 - val_loss: 0.0666 - val_accuracy: 0.9940\n",
      "Epoch 117/500\n",
      "33600/33600 [==============================] - 101s 3ms/step - loss: 0.0194 - accuracy: 0.9957 - val_loss: 0.0835 - val_accuracy: 0.9932\n",
      "Epoch 118/500\n",
      "33600/33600 [==============================] - 100s 3ms/step - loss: 0.0171 - accuracy: 0.9961 - val_loss: 0.0630 - val_accuracy: 0.9938\n",
      "Epoch 119/500\n",
      "33600/33600 [==============================] - 100s 3ms/step - loss: 0.0261 - accuracy: 0.9959 - val_loss: 0.0505 - val_accuracy: 0.9933\n",
      "Epoch 120/500\n",
      "33600/33600 [==============================] - 101s 3ms/step - loss: 0.0214 - accuracy: 0.9960 - val_loss: 0.0616 - val_accuracy: 0.9942\n",
      "Epoch 121/500\n",
      "33600/33600 [==============================] - 105s 3ms/step - loss: 0.0176 - accuracy: 0.9967 - val_loss: 0.0499 - val_accuracy: 0.9946\n",
      "Epoch 122/500\n",
      "33600/33600 [==============================] - 102s 3ms/step - loss: 0.0216 - accuracy: 0.9961 - val_loss: 0.0426 - val_accuracy: 0.9924\n",
      "Epoch 123/500\n",
      "33600/33600 [==============================] - 102s 3ms/step - loss: 0.0175 - accuracy: 0.9965 - val_loss: 0.0550 - val_accuracy: 0.9938\n",
      "Epoch 124/500\n",
      "33600/33600 [==============================] - 103s 3ms/step - loss: 0.0208 - accuracy: 0.9960 - val_loss: 0.0576 - val_accuracy: 0.9932\n",
      "Epoch 125/500\n",
      "33600/33600 [==============================] - 102s 3ms/step - loss: 0.0204 - accuracy: 0.9963 - val_loss: 0.0636 - val_accuracy: 0.9943\n",
      "Epoch 126/500\n",
      "33600/33600 [==============================] - 102s 3ms/step - loss: 0.0176 - accuracy: 0.9964 - val_loss: 0.0547 - val_accuracy: 0.9913\n",
      "Epoch 127/500\n",
      "33600/33600 [==============================] - 102s 3ms/step - loss: 0.0200 - accuracy: 0.9962 - val_loss: 0.0616 - val_accuracy: 0.9940\n",
      "Epoch 128/500\n",
      "33600/33600 [==============================] - 102s 3ms/step - loss: 0.0224 - accuracy: 0.9958 - val_loss: 0.0523 - val_accuracy: 0.9926\n",
      "Epoch 129/500\n",
      "33600/33600 [==============================] - 102s 3ms/step - loss: 0.0181 - accuracy: 0.9964 - val_loss: 0.0584 - val_accuracy: 0.9935\n",
      "Epoch 130/500\n",
      "33600/33600 [==============================] - 102s 3ms/step - loss: 0.0154 - accuracy: 0.9966 - val_loss: 0.0959 - val_accuracy: 0.9933\n",
      "Epoch 131/500\n",
      "33600/33600 [==============================] - 103s 3ms/step - loss: 0.0155 - accuracy: 0.9968 - val_loss: 0.0442 - val_accuracy: 0.9940\n",
      "Epoch 132/500\n",
      "33600/33600 [==============================] - 102s 3ms/step - loss: 0.0161 - accuracy: 0.9963 - val_loss: 0.0306 - val_accuracy: 0.9935\n",
      "Epoch 133/500\n",
      "33600/33600 [==============================] - 103s 3ms/step - loss: 0.0191 - accuracy: 0.9959 - val_loss: 0.0612 - val_accuracy: 0.9919\n",
      "Epoch 134/500\n",
      "33600/33600 [==============================] - 102s 3ms/step - loss: 0.0202 - accuracy: 0.9961 - val_loss: 0.0504 - val_accuracy: 0.9937\n",
      "Epoch 135/500\n",
      "33600/33600 [==============================] - 101s 3ms/step - loss: 0.0165 - accuracy: 0.9966 - val_loss: 0.0655 - val_accuracy: 0.9926\n",
      "Epoch 136/500\n",
      "33600/33600 [==============================] - 102s 3ms/step - loss: 0.0214 - accuracy: 0.9961 - val_loss: 0.0507 - val_accuracy: 0.9919\n",
      "Epoch 137/500\n",
      "33600/33600 [==============================] - 102s 3ms/step - loss: 0.0180 - accuracy: 0.9958 - val_loss: 0.0405 - val_accuracy: 0.9906\n",
      "Epoch 138/500\n",
      "33600/33600 [==============================] - 102s 3ms/step - loss: 0.0186 - accuracy: 0.9961 - val_loss: 0.0474 - val_accuracy: 0.9932\n",
      "Epoch 139/500\n",
      "33600/33600 [==============================] - 102s 3ms/step - loss: 0.0152 - accuracy: 0.9967 - val_loss: 0.0617 - val_accuracy: 0.9930\n",
      "Epoch 140/500\n",
      "33600/33600 [==============================] - 103s 3ms/step - loss: 0.0191 - accuracy: 0.9964 - val_loss: 0.0459 - val_accuracy: 0.9927\n",
      "Epoch 141/500\n",
      "33600/33600 [==============================] - 102s 3ms/step - loss: 0.0192 - accuracy: 0.9967 - val_loss: 0.0571 - val_accuracy: 0.9939\n",
      "Epoch 142/500\n",
      "33600/33600 [==============================] - 102s 3ms/step - loss: 0.0184 - accuracy: 0.9967 - val_loss: 0.0625 - val_accuracy: 0.9920\n",
      "Epoch 143/500\n",
      "33600/33600 [==============================] - 101s 3ms/step - loss: 0.0240 - accuracy: 0.9962 - val_loss: 0.0479 - val_accuracy: 0.9920\n",
      "Epoch 144/500\n",
      "33600/33600 [==============================] - 101s 3ms/step - loss: 0.0216 - accuracy: 0.9963 - val_loss: 0.0660 - val_accuracy: 0.9898\n",
      "Epoch 145/500\n",
      "33600/33600 [==============================] - 102s 3ms/step - loss: 0.0226 - accuracy: 0.9961 - val_loss: 0.0461 - val_accuracy: 0.9929\n",
      "Epoch 146/500\n",
      "33600/33600 [==============================] - 102s 3ms/step - loss: 0.0214 - accuracy: 0.9960 - val_loss: 0.0497 - val_accuracy: 0.9918\n",
      "Epoch 147/500\n",
      "33600/33600 [==============================] - 102s 3ms/step - loss: 0.0261 - accuracy: 0.9951 - val_loss: 0.0406 - val_accuracy: 0.9890\n",
      "Epoch 148/500\n",
      "33600/33600 [==============================] - 102s 3ms/step - loss: 0.0218 - accuracy: 0.9960 - val_loss: 0.0533 - val_accuracy: 0.9936\n",
      "Epoch 149/500\n",
      "33600/33600 [==============================] - 102s 3ms/step - loss: 0.0190 - accuracy: 0.9961 - val_loss: 0.0473 - val_accuracy: 0.9937\n",
      "Epoch 150/500\n",
      "33600/33600 [==============================] - 101s 3ms/step - loss: 0.0240 - accuracy: 0.9956 - val_loss: 0.0514 - val_accuracy: 0.9932\n",
      "Epoch 151/500\n",
      "33600/33600 [==============================] - 103s 3ms/step - loss: 0.0232 - accuracy: 0.9956 - val_loss: 0.0654 - val_accuracy: 0.9935\n",
      "Epoch 152/500\n",
      "33600/33600 [==============================] - 102s 3ms/step - loss: 0.0165 - accuracy: 0.9962 - val_loss: 0.0469 - val_accuracy: 0.9933\n",
      "Epoch 153/500\n",
      "33600/33600 [==============================] - 102s 3ms/step - loss: 0.0223 - accuracy: 0.9963 - val_loss: 0.0403 - val_accuracy: 0.9917\n",
      "Epoch 154/500\n",
      "33600/33600 [==============================] - 103s 3ms/step - loss: 0.0194 - accuracy: 0.9963 - val_loss: 0.0525 - val_accuracy: 0.9932\n",
      "Epoch 155/500\n",
      "33600/33600 [==============================] - 101s 3ms/step - loss: 0.0259 - accuracy: 0.9957 - val_loss: 0.0392 - val_accuracy: 0.9936\n",
      "Epoch 156/500\n",
      "33600/33600 [==============================] - 101s 3ms/step - loss: 0.0157 - accuracy: 0.9966 - val_loss: 0.0725 - val_accuracy: 0.9950\n",
      "Epoch 157/500\n",
      "33600/33600 [==============================] - 101s 3ms/step - loss: 0.0239 - accuracy: 0.9961 - val_loss: 0.0536 - val_accuracy: 0.9929\n",
      "Epoch 158/500\n",
      "33600/33600 [==============================] - 101s 3ms/step - loss: 0.0254 - accuracy: 0.9955 - val_loss: 0.0419 - val_accuracy: 0.9908\n",
      "Epoch 159/500\n",
      "33600/33600 [==============================] - 102s 3ms/step - loss: 0.0279 - accuracy: 0.9964 - val_loss: 0.0404 - val_accuracy: 0.9907\n",
      "Epoch 160/500\n",
      "33600/33600 [==============================] - 102s 3ms/step - loss: 0.0191 - accuracy: 0.9960 - val_loss: 0.0684 - val_accuracy: 0.9939\n",
      "Epoch 161/500\n",
      "33600/33600 [==============================] - 101s 3ms/step - loss: 0.0195 - accuracy: 0.9963 - val_loss: 0.0693 - val_accuracy: 0.9948\n",
      "Epoch 162/500\n",
      "33600/33600 [==============================] - 102s 3ms/step - loss: 0.0212 - accuracy: 0.9957 - val_loss: 0.0607 - val_accuracy: 0.9933\n",
      "Epoch 163/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33600/33600 [==============================] - 102s 3ms/step - loss: 0.0237 - accuracy: 0.9957 - val_loss: 0.0610 - val_accuracy: 0.9931\n",
      "Epoch 164/500\n",
      "33600/33600 [==============================] - 101s 3ms/step - loss: 0.0205 - accuracy: 0.9956 - val_loss: 0.0453 - val_accuracy: 0.9918\n",
      "Epoch 165/500\n",
      "33600/33600 [==============================] - 101s 3ms/step - loss: 0.0207 - accuracy: 0.9959 - val_loss: 0.0996 - val_accuracy: 0.9911\n",
      "Epoch 166/500\n",
      "33600/33600 [==============================] - 101s 3ms/step - loss: 0.0236 - accuracy: 0.9964 - val_loss: 0.0366 - val_accuracy: 0.9940\n",
      "Epoch 167/500\n",
      "33600/33600 [==============================] - 101s 3ms/step - loss: 0.0197 - accuracy: 0.9960 - val_loss: 0.0906 - val_accuracy: 0.9929\n",
      "Epoch 168/500\n",
      "33600/33600 [==============================] - 100s 3ms/step - loss: 0.0215 - accuracy: 0.9964 - val_loss: 0.0684 - val_accuracy: 0.9936\n",
      "Epoch 169/500\n",
      "33600/33600 [==============================] - 100s 3ms/step - loss: 0.0276 - accuracy: 0.9963 - val_loss: 0.0401 - val_accuracy: 0.9929\n",
      "Epoch 170/500\n",
      "33600/33600 [==============================] - 102s 3ms/step - loss: 0.0251 - accuracy: 0.9956 - val_loss: 0.0886 - val_accuracy: 0.9926\n",
      "Epoch 171/500\n",
      "33600/33600 [==============================] - 101s 3ms/step - loss: 0.0233 - accuracy: 0.9958 - val_loss: 0.0411 - val_accuracy: 0.9914\n",
      "Epoch 172/500\n",
      "33600/33600 [==============================] - 101s 3ms/step - loss: 0.0278 - accuracy: 0.9962 - val_loss: 0.0935 - val_accuracy: 0.9942\n",
      "Epoch 173/500\n",
      "33600/33600 [==============================] - 101s 3ms/step - loss: 0.0204 - accuracy: 0.9963 - val_loss: 0.0927 - val_accuracy: 0.9925\n",
      "Epoch 174/500\n",
      "33600/33600 [==============================] - 101s 3ms/step - loss: 0.0213 - accuracy: 0.9963 - val_loss: 0.0549 - val_accuracy: 0.9935\n",
      "Epoch 175/500\n",
      "33600/33600 [==============================] - 102s 3ms/step - loss: 0.0247 - accuracy: 0.9958 - val_loss: 0.0738 - val_accuracy: 0.9936\n",
      "Epoch 176/500\n",
      "33600/33600 [==============================] - 102s 3ms/step - loss: 0.0249 - accuracy: 0.9955 - val_loss: 0.0471 - val_accuracy: 0.9876\n",
      "Epoch 177/500\n",
      "33600/33600 [==============================] - 102s 3ms/step - loss: 0.0215 - accuracy: 0.9961 - val_loss: 0.0456 - val_accuracy: 0.9915\n",
      "Epoch 178/500\n",
      "33600/33600 [==============================] - 103s 3ms/step - loss: 0.0220 - accuracy: 0.9966 - val_loss: 0.0530 - val_accuracy: 0.9924\n",
      "Epoch 179/500\n",
      "33600/33600 [==============================] - 102s 3ms/step - loss: 0.0289 - accuracy: 0.9957 - val_loss: 0.0509 - val_accuracy: 0.9945\n",
      "Epoch 180/500\n",
      "33600/33600 [==============================] - 102s 3ms/step - loss: 0.0244 - accuracy: 0.9959 - val_loss: 0.0553 - val_accuracy: 0.9924\n",
      "Epoch 181/500\n",
      "33600/33600 [==============================] - 105s 3ms/step - loss: 0.0238 - accuracy: 0.9953 - val_loss: 0.0585 - val_accuracy: 0.9936\n",
      "Epoch 182/500\n",
      "33600/33600 [==============================] - 102s 3ms/step - loss: 0.0232 - accuracy: 0.9962 - val_loss: 0.0649 - val_accuracy: 0.9930\n",
      "Epoch 183/500\n",
      "33600/33600 [==============================] - 101s 3ms/step - loss: 0.0268 - accuracy: 0.9959 - val_loss: 0.0565 - val_accuracy: 0.9925\n",
      "Epoch 184/500\n",
      "33600/33600 [==============================] - 102s 3ms/step - loss: 0.0187 - accuracy: 0.9969 - val_loss: 0.0595 - val_accuracy: 0.9926\n",
      "Epoch 185/500\n",
      "33600/33600 [==============================] - 103s 3ms/step - loss: 0.0223 - accuracy: 0.9960 - val_loss: 0.0573 - val_accuracy: 0.9935\n",
      "Epoch 186/500\n",
      "33600/33600 [==============================] - 106s 3ms/step - loss: 0.0282 - accuracy: 0.9955 - val_loss: 0.0750 - val_accuracy: 0.9925\n",
      "Epoch 187/500\n",
      "33600/33600 [==============================] - 104s 3ms/step - loss: 0.0269 - accuracy: 0.9957 - val_loss: 0.0447 - val_accuracy: 0.9930\n",
      "Epoch 188/500\n",
      "33600/33600 [==============================] - 102s 3ms/step - loss: 0.0248 - accuracy: 0.9963 - val_loss: 0.0537 - val_accuracy: 0.9932\n",
      "Epoch 189/500\n",
      "33600/33600 [==============================] - 103s 3ms/step - loss: 0.0249 - accuracy: 0.9955 - val_loss: 0.0578 - val_accuracy: 0.9929\n",
      "Epoch 190/500\n",
      "33600/33600 [==============================] - 102s 3ms/step - loss: 0.0304 - accuracy: 0.9953 - val_loss: 0.0613 - val_accuracy: 0.9932\n",
      "Epoch 191/500\n",
      "33600/33600 [==============================] - 102s 3ms/step - loss: 0.0261 - accuracy: 0.9958 - val_loss: 0.0360 - val_accuracy: 0.9926\n",
      "Epoch 192/500\n",
      "33600/33600 [==============================] - 102s 3ms/step - loss: 0.0217 - accuracy: 0.9959 - val_loss: 0.0715 - val_accuracy: 0.9940\n",
      "Epoch 193/500\n",
      "33600/33600 [==============================] - 104s 3ms/step - loss: 0.0236 - accuracy: 0.9957 - val_loss: 0.0491 - val_accuracy: 0.9921\n",
      "Epoch 194/500\n",
      "33600/33600 [==============================] - 103s 3ms/step - loss: 0.0265 - accuracy: 0.9954 - val_loss: 0.0453 - val_accuracy: 0.9902\n",
      "Epoch 195/500\n",
      "33600/33600 [==============================] - 103s 3ms/step - loss: 0.0225 - accuracy: 0.9960 - val_loss: 0.1248 - val_accuracy: 0.9939\n",
      "Epoch 196/500\n",
      "33600/33600 [==============================] - 102s 3ms/step - loss: 0.0268 - accuracy: 0.9956 - val_loss: 0.0715 - val_accuracy: 0.9931\n",
      "Epoch 197/500\n",
      "33600/33600 [==============================] - 103s 3ms/step - loss: 0.0264 - accuracy: 0.9958 - val_loss: 0.0766 - val_accuracy: 0.9926\n",
      "Epoch 198/500\n",
      "33600/33600 [==============================] - 103s 3ms/step - loss: 0.0316 - accuracy: 0.9957 - val_loss: 0.0501 - val_accuracy: 0.9935\n",
      "Epoch 199/500\n",
      "33600/33600 [==============================] - 102s 3ms/step - loss: 0.0210 - accuracy: 0.9960 - val_loss: 0.0680 - val_accuracy: 0.9921\n",
      "Epoch 200/500\n",
      "33600/33600 [==============================] - 106s 3ms/step - loss: 0.0288 - accuracy: 0.9948 - val_loss: 0.0712 - val_accuracy: 0.9930\n",
      "Epoch 201/500\n",
      "33600/33600 [==============================] - 103s 3ms/step - loss: 0.0291 - accuracy: 0.9965 - val_loss: 0.1088 - val_accuracy: 0.9925\n",
      "Epoch 202/500\n",
      "33600/33600 [==============================] - 102s 3ms/step - loss: 0.0273 - accuracy: 0.9957 - val_loss: 0.0645 - val_accuracy: 0.9927\n",
      "Epoch 203/500\n",
      "33600/33600 [==============================] - 103s 3ms/step - loss: 0.0220 - accuracy: 0.9960 - val_loss: 0.0601 - val_accuracy: 0.9933\n",
      "Epoch 204/500\n",
      "33600/33600 [==============================] - 104s 3ms/step - loss: 0.0254 - accuracy: 0.9958 - val_loss: 0.0600 - val_accuracy: 0.9935\n",
      "Epoch 205/500\n",
      "33600/33600 [==============================] - 103s 3ms/step - loss: 0.0253 - accuracy: 0.9953 - val_loss: 0.0496 - val_accuracy: 0.9927\n",
      "Epoch 206/500\n",
      "33600/33600 [==============================] - 106s 3ms/step - loss: 0.0239 - accuracy: 0.9953 - val_loss: 0.0895 - val_accuracy: 0.9939\n",
      "Epoch 207/500\n",
      "33600/33600 [==============================] - 103s 3ms/step - loss: 0.0223 - accuracy: 0.9965 - val_loss: 0.0955 - val_accuracy: 0.9935\n",
      "Epoch 208/500\n",
      "33600/33600 [==============================] - 103s 3ms/step - loss: 0.0272 - accuracy: 0.9963 - val_loss: 0.0759 - val_accuracy: 0.9946\n",
      "Epoch 209/500\n",
      "33600/33600 [==============================] - 103s 3ms/step - loss: 0.0299 - accuracy: 0.9954 - val_loss: 0.0937 - val_accuracy: 0.9946\n",
      "Epoch 210/500\n",
      "33600/33600 [==============================] - 104s 3ms/step - loss: 0.0319 - accuracy: 0.9955 - val_loss: 0.0587 - val_accuracy: 0.9925\n",
      "Epoch 211/500\n",
      "33600/33600 [==============================] - 103s 3ms/step - loss: 0.0289 - accuracy: 0.9952 - val_loss: 0.0561 - val_accuracy: 0.9932\n",
      "Epoch 212/500\n",
      "33600/33600 [==============================] - 103s 3ms/step - loss: 0.0398 - accuracy: 0.9953 - val_loss: 0.0549 - val_accuracy: 0.9942\n",
      "Epoch 213/500\n",
      "33600/33600 [==============================] - 103s 3ms/step - loss: 0.0286 - accuracy: 0.9956 - val_loss: 0.0764 - val_accuracy: 0.9935\n",
      "Epoch 214/500\n",
      "33600/33600 [==============================] - 102s 3ms/step - loss: 0.0205 - accuracy: 0.9965 - val_loss: 0.0716 - val_accuracy: 0.9932\n",
      "Epoch 215/500\n",
      "33600/33600 [==============================] - 103s 3ms/step - loss: 0.0239 - accuracy: 0.9969 - val_loss: 0.0623 - val_accuracy: 0.9835\n",
      "Epoch 216/500\n",
      "33600/33600 [==============================] - 104s 3ms/step - loss: 0.0293 - accuracy: 0.9958 - val_loss: 0.0844 - val_accuracy: 0.9919\n",
      "Epoch 217/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33600/33600 [==============================] - 103s 3ms/step - loss: 0.0378 - accuracy: 0.9954 - val_loss: 0.0472 - val_accuracy: 0.9892\n",
      "Epoch 218/500\n",
      "33600/33600 [==============================] - 103s 3ms/step - loss: 0.0281 - accuracy: 0.9949 - val_loss: 0.0533 - val_accuracy: 0.9932\n",
      "Epoch 219/500\n",
      "33600/33600 [==============================] - 103s 3ms/step - loss: 0.0240 - accuracy: 0.9963 - val_loss: 0.0825 - val_accuracy: 0.9938\n",
      "Epoch 220/500\n",
      "33600/33600 [==============================] - 102s 3ms/step - loss: 0.0223 - accuracy: 0.9960 - val_loss: 0.1707 - val_accuracy: 0.9940\n",
      "Epoch 221/500\n",
      "33600/33600 [==============================] - 103s 3ms/step - loss: 0.0399 - accuracy: 0.9946 - val_loss: 0.0646 - val_accuracy: 0.9930\n",
      "Epoch 222/500\n",
      "33600/33600 [==============================] - 102s 3ms/step - loss: 0.0263 - accuracy: 0.9961 - val_loss: 0.0643 - val_accuracy: 0.9925\n",
      "Epoch 223/500\n",
      "33600/33600 [==============================] - 102s 3ms/step - loss: 0.0296 - accuracy: 0.9960 - val_loss: 0.0496 - val_accuracy: 0.9932\n",
      "Epoch 224/500\n",
      "33600/33600 [==============================] - 102s 3ms/step - loss: 0.0205 - accuracy: 0.9961 - val_loss: 0.0464 - val_accuracy: 0.9883\n",
      "Epoch 225/500\n",
      "33600/33600 [==============================] - 103s 3ms/step - loss: 0.0241 - accuracy: 0.9962 - val_loss: 0.0872 - val_accuracy: 0.9940\n",
      "Epoch 226/500\n",
      "33600/33600 [==============================] - 102s 3ms/step - loss: 0.0278 - accuracy: 0.9958 - val_loss: 0.0577 - val_accuracy: 0.9899\n",
      "Epoch 227/500\n",
      "33600/33600 [==============================] - 103s 3ms/step - loss: 0.0266 - accuracy: 0.9949 - val_loss: 0.1248 - val_accuracy: 0.9940\n",
      "Epoch 228/500\n",
      "33600/33600 [==============================] - 103s 3ms/step - loss: 0.0236 - accuracy: 0.9958 - val_loss: 0.0824 - val_accuracy: 0.9926\n",
      "Epoch 229/500\n",
      "33600/33600 [==============================] - 102s 3ms/step - loss: 0.0328 - accuracy: 0.9951 - val_loss: 0.0583 - val_accuracy: 0.9937\n",
      "Epoch 230/500\n",
      "33600/33600 [==============================] - 103s 3ms/step - loss: 0.0203 - accuracy: 0.9965 - val_loss: 0.0807 - val_accuracy: 0.9938\n",
      "Epoch 231/500\n",
      "33600/33600 [==============================] - 103s 3ms/step - loss: 0.0295 - accuracy: 0.9965 - val_loss: 0.0688 - val_accuracy: 0.9935\n",
      "Epoch 232/500\n",
      "33600/33600 [==============================] - 103s 3ms/step - loss: 0.0323 - accuracy: 0.9954 - val_loss: 0.0781 - val_accuracy: 0.9931\n",
      "Epoch 233/500\n",
      "33600/33600 [==============================] - 104s 3ms/step - loss: 0.0238 - accuracy: 0.9962 - val_loss: 0.1138 - val_accuracy: 0.9924\n",
      "Epoch 234/500\n",
      "33600/33600 [==============================] - 102s 3ms/step - loss: 0.0351 - accuracy: 0.9953 - val_loss: 0.0668 - val_accuracy: 0.9938\n",
      "Epoch 235/500\n",
      "33600/33600 [==============================] - 103s 3ms/step - loss: 0.0239 - accuracy: 0.9962 - val_loss: 0.0954 - val_accuracy: 0.9923\n",
      "Epoch 236/500\n",
      "33600/33600 [==============================] - 103s 3ms/step - loss: 0.0349 - accuracy: 0.9953 - val_loss: 0.0679 - val_accuracy: 0.9943\n",
      "Epoch 237/500\n",
      "33600/33600 [==============================] - 102s 3ms/step - loss: 0.0302 - accuracy: 0.9958 - val_loss: 0.0684 - val_accuracy: 0.9921\n",
      "Epoch 238/500\n",
      "33600/33600 [==============================] - 102s 3ms/step - loss: 0.0248 - accuracy: 0.9963 - val_loss: 0.1053 - val_accuracy: 0.9929\n",
      "Epoch 239/500\n",
      "33600/33600 [==============================] - 102s 3ms/step - loss: 0.0311 - accuracy: 0.9962 - val_loss: 0.0583 - val_accuracy: 0.9933\n",
      "Epoch 240/500\n",
      "33600/33600 [==============================] - 102s 3ms/step - loss: 0.0346 - accuracy: 0.9951 - val_loss: 0.0873 - val_accuracy: 0.9939\n",
      "Epoch 241/500\n",
      "33600/33600 [==============================] - 103s 3ms/step - loss: 0.0290 - accuracy: 0.9958 - val_loss: 0.0568 - val_accuracy: 0.9924\n",
      "Epoch 242/500\n",
      "33600/33600 [==============================] - 103s 3ms/step - loss: 0.0219 - accuracy: 0.9960 - val_loss: 0.0675 - val_accuracy: 0.9930\n",
      "Epoch 243/500\n",
      "33600/33600 [==============================] - 104s 3ms/step - loss: 0.0314 - accuracy: 0.9946 - val_loss: 0.0582 - val_accuracy: 0.9935\n",
      "Epoch 244/500\n",
      "33600/33600 [==============================] - 102s 3ms/step - loss: 0.0324 - accuracy: 0.9957 - val_loss: 0.0724 - val_accuracy: 0.9936\n",
      "Epoch 245/500\n",
      "33600/33600 [==============================] - 103s 3ms/step - loss: 0.0372 - accuracy: 0.9949 - val_loss: 0.0772 - val_accuracy: 0.9920\n",
      "Epoch 246/500\n",
      "33600/33600 [==============================] - 103s 3ms/step - loss: 0.0284 - accuracy: 0.9960 - val_loss: 0.0695 - val_accuracy: 0.9918\n",
      "Epoch 247/500\n",
      "33600/33600 [==============================] - 102s 3ms/step - loss: 0.0278 - accuracy: 0.9957 - val_loss: 0.0668 - val_accuracy: 0.9942\n",
      "Epoch 248/500\n",
      "33600/33600 [==============================] - 102s 3ms/step - loss: 0.0321 - accuracy: 0.9955 - val_loss: 0.0602 - val_accuracy: 0.9913\n",
      "Epoch 249/500\n",
      "33600/33600 [==============================] - 102s 3ms/step - loss: 0.0286 - accuracy: 0.9956 - val_loss: 0.1029 - val_accuracy: 0.9943\n",
      "Epoch 250/500\n",
      "33600/33600 [==============================] - 102s 3ms/step - loss: 0.0237 - accuracy: 0.9960 - val_loss: 0.0846 - val_accuracy: 0.9929\n",
      "Epoch 251/500\n",
      "33600/33600 [==============================] - 102s 3ms/step - loss: 0.0302 - accuracy: 0.9963 - val_loss: 0.0718 - val_accuracy: 0.9929\n",
      "Epoch 252/500\n",
      "33600/33600 [==============================] - 102s 3ms/step - loss: 0.0274 - accuracy: 0.9951 - val_loss: 0.0778 - val_accuracy: 0.9945\n",
      "Epoch 253/500\n",
      "33600/33600 [==============================] - 102s 3ms/step - loss: 0.0291 - accuracy: 0.9953 - val_loss: 0.0763 - val_accuracy: 0.9938\n",
      "Epoch 254/500\n",
      "33600/33600 [==============================] - 103s 3ms/step - loss: 0.0286 - accuracy: 0.9954 - val_loss: 0.0758 - val_accuracy: 0.9926\n",
      "Epoch 255/500\n",
      "33600/33600 [==============================] - 102s 3ms/step - loss: 0.0312 - accuracy: 0.9953 - val_loss: 0.0549 - val_accuracy: 0.9930\n",
      "Epoch 256/500\n",
      "33600/33600 [==============================] - 105s 3ms/step - loss: 0.0337 - accuracy: 0.9959 - val_loss: 0.0551 - val_accuracy: 0.9925\n",
      "Epoch 257/500\n",
      "33600/33600 [==============================] - 103s 3ms/step - loss: 0.0327 - accuracy: 0.9952 - val_loss: 0.1082 - val_accuracy: 0.9911\n",
      "Epoch 258/500\n",
      "33600/33600 [==============================] - 102s 3ms/step - loss: 0.0369 - accuracy: 0.9951 - val_loss: 0.0516 - val_accuracy: 0.9929\n",
      "Epoch 259/500\n",
      "33600/33600 [==============================] - 102s 3ms/step - loss: 0.0274 - accuracy: 0.9955 - val_loss: 0.0623 - val_accuracy: 0.9930\n",
      "Epoch 260/500\n",
      "33600/33600 [==============================] - 105s 3ms/step - loss: 0.0417 - accuracy: 0.9958 - val_loss: 0.0703 - val_accuracy: 0.9937\n",
      "Epoch 261/500\n",
      "33600/33600 [==============================] - 103s 3ms/step - loss: 0.0236 - accuracy: 0.9962 - val_loss: 0.0625 - val_accuracy: 0.9944\n",
      "Epoch 262/500\n",
      "33600/33600 [==============================] - 102s 3ms/step - loss: 0.0322 - accuracy: 0.9958 - val_loss: 0.0662 - val_accuracy: 0.9938\n",
      "Epoch 263/500\n",
      "33600/33600 [==============================] - 102s 3ms/step - loss: 0.0307 - accuracy: 0.9949 - val_loss: 0.0643 - val_accuracy: 0.9918\n",
      "Epoch 264/500\n",
      "33600/33600 [==============================] - 103s 3ms/step - loss: 0.0251 - accuracy: 0.9956 - val_loss: 0.0650 - val_accuracy: 0.9929\n",
      "Epoch 265/500\n",
      "33600/33600 [==============================] - 103s 3ms/step - loss: 0.0273 - accuracy: 0.9957 - val_loss: 0.1060 - val_accuracy: 0.9939\n",
      "Epoch 266/500\n",
      "33600/33600 [==============================] - 103s 3ms/step - loss: 0.0247 - accuracy: 0.9959 - val_loss: 0.0587 - val_accuracy: 0.9840\n",
      "Epoch 267/500\n",
      "33600/33600 [==============================] - 103s 3ms/step - loss: 0.0274 - accuracy: 0.9960 - val_loss: 0.1021 - val_accuracy: 0.9933\n",
      "Epoch 268/500\n",
      "33600/33600 [==============================] - 103s 3ms/step - loss: 0.0314 - accuracy: 0.9956 - val_loss: 0.0677 - val_accuracy: 0.9908\n",
      "Epoch 269/500\n",
      "33600/33600 [==============================] - 103s 3ms/step - loss: 0.0288 - accuracy: 0.9955 - val_loss: 0.1063 - val_accuracy: 0.9946\n",
      "Epoch 270/500\n",
      "33600/33600 [==============================] - 103s 3ms/step - loss: 0.0233 - accuracy: 0.9965 - val_loss: 0.0709 - val_accuracy: 0.9942\n",
      "Epoch 271/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33600/33600 [==============================] - 102s 3ms/step - loss: 0.0319 - accuracy: 0.9960 - val_loss: 0.0639 - val_accuracy: 0.9906\n",
      "Epoch 272/500\n",
      "33600/33600 [==============================] - 103s 3ms/step - loss: 0.0238 - accuracy: 0.9955 - val_loss: 0.0819 - val_accuracy: 0.9933\n",
      "Epoch 273/500\n",
      "33600/33600 [==============================] - 103s 3ms/step - loss: 0.0291 - accuracy: 0.9954 - val_loss: 0.0613 - val_accuracy: 0.9925\n",
      "Epoch 274/500\n",
      "33600/33600 [==============================] - 103s 3ms/step - loss: 0.0262 - accuracy: 0.9953 - val_loss: 0.0634 - val_accuracy: 0.9931\n",
      "Epoch 275/500\n",
      "33600/33600 [==============================] - 102s 3ms/step - loss: 0.0336 - accuracy: 0.9941 - val_loss: 0.1531 - val_accuracy: 0.9932\n",
      "Epoch 276/500\n",
      "33600/33600 [==============================] - 102s 3ms/step - loss: 0.0345 - accuracy: 0.9956 - val_loss: 0.0814 - val_accuracy: 0.9948\n",
      "Epoch 277/500\n",
      "33600/33600 [==============================] - 103s 3ms/step - loss: 0.0291 - accuracy: 0.9955 - val_loss: 0.0754 - val_accuracy: 0.9927\n",
      "Epoch 278/500\n",
      "33600/33600 [==============================] - 102s 3ms/step - loss: 0.0390 - accuracy: 0.9945 - val_loss: 0.0862 - val_accuracy: 0.9883\n",
      "Epoch 279/500\n",
      "33600/33600 [==============================] - 102s 3ms/step - loss: 0.0389 - accuracy: 0.9941 - val_loss: 0.0665 - val_accuracy: 0.9938\n",
      "Epoch 280/500\n",
      "33600/33600 [==============================] - 102s 3ms/step - loss: 0.0273 - accuracy: 0.9960 - val_loss: 0.0527 - val_accuracy: 0.9923\n",
      "Epoch 281/500\n",
      "33600/33600 [==============================] - 102s 3ms/step - loss: 0.0337 - accuracy: 0.9948 - val_loss: 0.0857 - val_accuracy: 0.9930\n",
      "Epoch 282/500\n",
      "33600/33600 [==============================] - 102s 3ms/step - loss: 0.0356 - accuracy: 0.9945 - val_loss: 0.0717 - val_accuracy: 0.9935\n",
      "Epoch 283/500\n",
      "33600/33600 [==============================] - 102s 3ms/step - loss: 0.0380 - accuracy: 0.9949 - val_loss: 0.0524 - val_accuracy: 0.9939\n",
      "Epoch 284/500\n",
      "33600/33600 [==============================] - 102s 3ms/step - loss: 0.0311 - accuracy: 0.9954 - val_loss: 0.0560 - val_accuracy: 0.9937\n",
      "Epoch 285/500\n",
      "33600/33600 [==============================] - 102s 3ms/step - loss: 0.0331 - accuracy: 0.9954 - val_loss: 0.0645 - val_accuracy: 0.9875\n",
      "Epoch 286/500\n",
      "33600/33600 [==============================] - 102s 3ms/step - loss: 0.0250 - accuracy: 0.9951 - val_loss: 0.0687 - val_accuracy: 0.9927\n",
      "Epoch 287/500\n",
      "33600/33600 [==============================] - 102s 3ms/step - loss: 0.0403 - accuracy: 0.9945 - val_loss: 0.0415 - val_accuracy: 0.9915\n",
      "Epoch 288/500\n",
      "33600/33600 [==============================] - 102s 3ms/step - loss: 0.0276 - accuracy: 0.9955 - val_loss: 0.0998 - val_accuracy: 0.9936\n",
      "Epoch 289/500\n",
      "33600/33600 [==============================] - 102s 3ms/step - loss: 0.0321 - accuracy: 0.9955 - val_loss: 0.0430 - val_accuracy: 0.9896\n",
      "Epoch 290/500\n",
      "33600/33600 [==============================] - 103s 3ms/step - loss: 0.0352 - accuracy: 0.9949 - val_loss: 0.0745 - val_accuracy: 0.9913\n",
      "Epoch 291/500\n",
      "33600/33600 [==============================] - 105s 3ms/step - loss: 0.0288 - accuracy: 0.9948 - val_loss: 0.0682 - val_accuracy: 0.9927\n",
      "Epoch 292/500\n",
      "33600/33600 [==============================] - 104s 3ms/step - loss: 0.0384 - accuracy: 0.9958 - val_loss: 0.0545 - val_accuracy: 0.9931\n",
      "Epoch 293/500\n",
      "33600/33600 [==============================] - 102s 3ms/step - loss: 0.0367 - accuracy: 0.9952 - val_loss: 0.0392 - val_accuracy: 0.9939\n",
      "Epoch 294/500\n",
      "33600/33600 [==============================] - 102s 3ms/step - loss: 0.0305 - accuracy: 0.9957 - val_loss: 0.0666 - val_accuracy: 0.9921\n",
      "Epoch 295/500\n",
      "33600/33600 [==============================] - 104s 3ms/step - loss: 0.0305 - accuracy: 0.9965 - val_loss: 0.1315 - val_accuracy: 0.9927\n",
      "Epoch 296/500\n",
      "33600/33600 [==============================] - 102s 3ms/step - loss: 0.0405 - accuracy: 0.9955 - val_loss: 0.0819 - val_accuracy: 0.9910\n",
      "Epoch 297/500\n",
      "33600/33600 [==============================] - 103s 3ms/step - loss: 0.0357 - accuracy: 0.9943 - val_loss: 0.0586 - val_accuracy: 0.9937\n",
      "Epoch 298/500\n",
      "33600/33600 [==============================] - 103s 3ms/step - loss: 0.0360 - accuracy: 0.9938 - val_loss: 0.0554 - val_accuracy: 0.9917\n",
      "Epoch 299/500\n",
      "33600/33600 [==============================] - 103s 3ms/step - loss: 0.0440 - accuracy: 0.9940 - val_loss: 0.0896 - val_accuracy: 0.9912\n",
      "Epoch 300/500\n",
      "33600/33600 [==============================] - 102s 3ms/step - loss: 0.0393 - accuracy: 0.9940 - val_loss: 0.0735 - val_accuracy: 0.9933\n",
      "Epoch 301/500\n",
      "33600/33600 [==============================] - 103s 3ms/step - loss: 0.0275 - accuracy: 0.9953 - val_loss: 0.0904 - val_accuracy: 0.9920\n",
      "Epoch 302/500\n",
      "33600/33600 [==============================] - 103s 3ms/step - loss: 0.0572 - accuracy: 0.9950 - val_loss: 0.0490 - val_accuracy: 0.9931\n",
      "Epoch 303/500\n",
      "33600/33600 [==============================] - 104s 3ms/step - loss: 0.0342 - accuracy: 0.9951 - val_loss: 0.1325 - val_accuracy: 0.9938\n",
      "Epoch 304/500\n",
      "33600/33600 [==============================] - 103s 3ms/step - loss: 0.0389 - accuracy: 0.9954 - val_loss: 0.0752 - val_accuracy: 0.9932\n",
      "Epoch 305/500\n",
      "33600/33600 [==============================] - 103s 3ms/step - loss: 0.0299 - accuracy: 0.9958 - val_loss: 0.1279 - val_accuracy: 0.9931\n",
      "Epoch 306/500\n",
      "33600/33600 [==============================] - 103s 3ms/step - loss: 0.0396 - accuracy: 0.9945 - val_loss: 0.1151 - val_accuracy: 0.9931\n",
      "Epoch 307/500\n",
      "33600/33600 [==============================] - 104s 3ms/step - loss: 0.0263 - accuracy: 0.9955 - val_loss: 0.0662 - val_accuracy: 0.9924\n",
      "Epoch 308/500\n",
      "33600/33600 [==============================] - 103s 3ms/step - loss: 0.0464 - accuracy: 0.9943 - val_loss: 0.0603 - val_accuracy: 0.9911\n",
      "Epoch 309/500\n",
      "33600/33600 [==============================] - 104s 3ms/step - loss: 0.0430 - accuracy: 0.9948 - val_loss: 0.0542 - val_accuracy: 0.9918\n",
      "Epoch 310/500\n",
      "33600/33600 [==============================] - 103s 3ms/step - loss: 0.0397 - accuracy: 0.9952 - val_loss: 0.0886 - val_accuracy: 0.9942\n",
      "Epoch 311/500\n",
      "33600/33600 [==============================] - 102s 3ms/step - loss: 0.0394 - accuracy: 0.9942 - val_loss: 0.0664 - val_accuracy: 0.9918\n",
      "Epoch 312/500\n",
      "33600/33600 [==============================] - 102s 3ms/step - loss: 0.0508 - accuracy: 0.9947 - val_loss: 0.0983 - val_accuracy: 0.9925\n",
      "Epoch 313/500\n",
      "33600/33600 [==============================] - 102s 3ms/step - loss: 0.0400 - accuracy: 0.9943 - val_loss: 0.0727 - val_accuracy: 0.9935\n",
      "Epoch 314/500\n",
      "33600/33600 [==============================] - 103s 3ms/step - loss: 0.0325 - accuracy: 0.9954 - val_loss: 0.0967 - val_accuracy: 0.9920\n",
      "Epoch 315/500\n",
      "33600/33600 [==============================] - 103s 3ms/step - loss: 0.0434 - accuracy: 0.9937 - val_loss: 0.0596 - val_accuracy: 0.9905\n",
      "Epoch 316/500\n",
      "33600/33600 [==============================] - 103s 3ms/step - loss: 0.0294 - accuracy: 0.9954 - val_loss: 0.0912 - val_accuracy: 0.9938\n",
      "Epoch 317/500\n",
      "33600/33600 [==============================] - 103s 3ms/step - loss: 0.0310 - accuracy: 0.9951 - val_loss: 0.0514 - val_accuracy: 0.9911\n",
      "Epoch 318/500\n",
      "33600/33600 [==============================] - 104s 3ms/step - loss: 0.0336 - accuracy: 0.9948 - val_loss: 0.0836 - val_accuracy: 0.9904\n",
      "Epoch 319/500\n",
      "33600/33600 [==============================] - 102s 3ms/step - loss: 0.0408 - accuracy: 0.9957 - val_loss: 0.0707 - val_accuracy: 0.9933\n",
      "Epoch 320/500\n",
      "33600/33600 [==============================] - 103s 3ms/step - loss: 0.0339 - accuracy: 0.9947 - val_loss: 0.0930 - val_accuracy: 0.9927\n",
      "Epoch 321/500\n",
      "33600/33600 [==============================] - 104s 3ms/step - loss: 0.0359 - accuracy: 0.9950 - val_loss: 0.0874 - val_accuracy: 0.9942\n",
      "Epoch 322/500\n",
      "33600/33600 [==============================] - 103s 3ms/step - loss: 0.0288 - accuracy: 0.9958 - val_loss: 0.1070 - val_accuracy: 0.9929\n",
      "Epoch 323/500\n",
      "33600/33600 [==============================] - 102s 3ms/step - loss: 0.0364 - accuracy: 0.9947 - val_loss: 0.0573 - val_accuracy: 0.9912\n",
      "Epoch 324/500\n",
      "33600/33600 [==============================] - 103s 3ms/step - loss: 0.0361 - accuracy: 0.9957 - val_loss: 0.0897 - val_accuracy: 0.9924\n",
      "Epoch 325/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33600/33600 [==============================] - 102s 3ms/step - loss: 0.0290 - accuracy: 0.9960 - val_loss: 0.0908 - val_accuracy: 0.9929\n",
      "Epoch 326/500\n",
      "33600/33600 [==============================] - 106s 3ms/step - loss: 0.0434 - accuracy: 0.9942 - val_loss: 0.0643 - val_accuracy: 0.9911\n",
      "Epoch 327/500\n",
      "33600/33600 [==============================] - 103s 3ms/step - loss: 0.0358 - accuracy: 0.9954 - val_loss: 0.0799 - val_accuracy: 0.9925\n",
      "Epoch 328/500\n",
      "33600/33600 [==============================] - 102s 3ms/step - loss: 0.0425 - accuracy: 0.9947 - val_loss: 0.0458 - val_accuracy: 0.9912\n",
      "Epoch 329/500\n",
      "33600/33600 [==============================] - 104s 3ms/step - loss: 0.0411 - accuracy: 0.9932 - val_loss: 0.0476 - val_accuracy: 0.9925\n",
      "Epoch 330/500\n",
      "33600/33600 [==============================] - 103s 3ms/step - loss: 0.0358 - accuracy: 0.9947 - val_loss: 0.0499 - val_accuracy: 0.9937\n",
      "Epoch 331/500\n",
      "33600/33600 [==============================] - 103s 3ms/step - loss: 0.0413 - accuracy: 0.9945 - val_loss: 0.2258 - val_accuracy: 0.9931\n",
      "Epoch 332/500\n",
      "33600/33600 [==============================] - 103s 3ms/step - loss: 0.0445 - accuracy: 0.9946 - val_loss: 0.0743 - val_accuracy: 0.9904\n",
      "Epoch 333/500\n",
      "33600/33600 [==============================] - 104s 3ms/step - loss: 0.0421 - accuracy: 0.9942 - val_loss: 0.1109 - val_accuracy: 0.9926\n",
      "Epoch 334/500\n",
      "33600/33600 [==============================] - 103s 3ms/step - loss: 0.0420 - accuracy: 0.9928 - val_loss: 0.0946 - val_accuracy: 0.9914\n",
      "Epoch 335/500\n",
      "33600/33600 [==============================] - 103s 3ms/step - loss: 0.0298 - accuracy: 0.9951 - val_loss: 0.1319 - val_accuracy: 0.9936\n",
      "Epoch 336/500\n",
      "33600/33600 [==============================] - 103s 3ms/step - loss: 0.0416 - accuracy: 0.9940 - val_loss: 0.0744 - val_accuracy: 0.9924\n",
      "Epoch 337/500\n",
      "33600/33600 [==============================] - 104s 3ms/step - loss: 0.0377 - accuracy: 0.9947 - val_loss: 0.0819 - val_accuracy: 0.9927\n",
      "Epoch 338/500\n",
      "33600/33600 [==============================] - 104s 3ms/step - loss: 0.0445 - accuracy: 0.9943 - val_loss: 0.0599 - val_accuracy: 0.9919\n",
      "Epoch 339/500\n",
      "33600/33600 [==============================] - 105s 3ms/step - loss: 0.0343 - accuracy: 0.9951 - val_loss: 0.0608 - val_accuracy: 0.9914\n",
      "Epoch 340/500\n",
      "33600/33600 [==============================] - 104s 3ms/step - loss: 0.0299 - accuracy: 0.9954 - val_loss: 0.0907 - val_accuracy: 0.9919\n",
      "Epoch 341/500\n",
      "33600/33600 [==============================] - 104s 3ms/step - loss: 0.0575 - accuracy: 0.9919 - val_loss: 0.0765 - val_accuracy: 0.9912\n",
      "Epoch 342/500\n",
      "33600/33600 [==============================] - 103s 3ms/step - loss: 0.0818 - accuracy: 0.9937 - val_loss: 0.0958 - val_accuracy: 0.9923\n",
      "Epoch 343/500\n",
      "33600/33600 [==============================] - 104s 3ms/step - loss: 0.0342 - accuracy: 0.9939 - val_loss: 0.1080 - val_accuracy: 0.9933\n",
      "Epoch 344/500\n",
      "33600/33600 [==============================] - 103s 3ms/step - loss: 0.0375 - accuracy: 0.9953 - val_loss: 0.0603 - val_accuracy: 0.9933\n",
      "Epoch 345/500\n",
      "33600/33600 [==============================] - 104s 3ms/step - loss: 0.0300 - accuracy: 0.9956 - val_loss: 0.1007 - val_accuracy: 0.9927\n",
      "Epoch 346/500\n",
      "33600/33600 [==============================] - 105s 3ms/step - loss: 0.0442 - accuracy: 0.9942 - val_loss: 0.0790 - val_accuracy: 0.9932\n",
      "Epoch 347/500\n",
      "33600/33600 [==============================] - 116s 3ms/step - loss: 0.0446 - accuracy: 0.9939 - val_loss: 0.2743 - val_accuracy: 0.9913\n",
      "Epoch 348/500\n",
      "33600/33600 [==============================] - 111s 3ms/step - loss: 0.0454 - accuracy: 0.9940 - val_loss: 0.0815 - val_accuracy: 0.9890\n",
      "Epoch 349/500\n",
      "33600/33600 [==============================] - 108s 3ms/step - loss: 0.0400 - accuracy: 0.9939 - val_loss: 0.1299 - val_accuracy: 0.9932\n",
      "Epoch 350/500\n",
      "33600/33600 [==============================] - 106s 3ms/step - loss: 0.0590 - accuracy: 0.9939 - val_loss: 0.0857 - val_accuracy: 0.9938\n",
      "Epoch 351/500\n",
      "33600/33600 [==============================] - 106s 3ms/step - loss: 0.0381 - accuracy: 0.9937 - val_loss: 0.0492 - val_accuracy: 0.9915\n",
      "Epoch 352/500\n",
      "33600/33600 [==============================] - 107s 3ms/step - loss: 0.0405 - accuracy: 0.9940 - val_loss: 0.1486 - val_accuracy: 0.9937\n",
      "Epoch 353/500\n",
      "33600/33600 [==============================] - 116s 3ms/step - loss: 0.0405 - accuracy: 0.9934 - val_loss: 0.1128 - val_accuracy: 0.9910\n",
      "Epoch 354/500\n",
      "33600/33600 [==============================] - 107s 3ms/step - loss: 0.0436 - accuracy: 0.9946 - val_loss: 0.1604 - val_accuracy: 0.9918\n",
      "Epoch 355/500\n",
      "33600/33600 [==============================] - 113s 3ms/step - loss: 0.0410 - accuracy: 0.9949 - val_loss: 0.1362 - val_accuracy: 0.9942\n",
      "Epoch 356/500\n",
      "33600/33600 [==============================] - 108s 3ms/step - loss: 0.0434 - accuracy: 0.9942 - val_loss: 0.1007 - val_accuracy: 0.9936\n",
      "Epoch 357/500\n",
      "33600/33600 [==============================] - 112s 3ms/step - loss: 0.0447 - accuracy: 0.9949 - val_loss: 0.0499 - val_accuracy: 0.9918\n",
      "Epoch 358/500\n",
      "33600/33600 [==============================] - 112s 3ms/step - loss: 0.0431 - accuracy: 0.9941 - val_loss: 0.0989 - val_accuracy: 0.9931\n",
      "Epoch 359/500\n",
      "33600/33600 [==============================] - 106s 3ms/step - loss: 0.0395 - accuracy: 0.9940 - val_loss: 0.0763 - val_accuracy: 0.9938\n",
      "Epoch 360/500\n",
      "33600/33600 [==============================] - 109s 3ms/step - loss: 0.0454 - accuracy: 0.9930 - val_loss: 0.0471 - val_accuracy: 0.9912\n",
      "Epoch 361/500\n",
      "33600/33600 [==============================] - 107s 3ms/step - loss: 0.0432 - accuracy: 0.9941 - val_loss: 0.0797 - val_accuracy: 0.9924\n",
      "Epoch 362/500\n",
      "33600/33600 [==============================] - 106s 3ms/step - loss: 0.0452 - accuracy: 0.9938 - val_loss: 0.0656 - val_accuracy: 0.9926\n",
      "Epoch 363/500\n",
      "33600/33600 [==============================] - 106s 3ms/step - loss: 0.0461 - accuracy: 0.9941 - val_loss: 0.0850 - val_accuracy: 0.9931\n",
      "Epoch 364/500\n",
      "33600/33600 [==============================] - 112s 3ms/step - loss: 0.0509 - accuracy: 0.9946 - val_loss: 0.1012 - val_accuracy: 0.9936\n",
      "Epoch 365/500\n",
      "33600/33600 [==============================] - 137s 4ms/step - loss: 0.0364 - accuracy: 0.9943 - val_loss: 0.0648 - val_accuracy: 0.9942\n",
      "Epoch 366/500\n",
      "33600/33600 [==============================] - 114s 3ms/step - loss: 0.0612 - accuracy: 0.9942 - val_loss: 0.0649 - val_accuracy: 0.9882\n",
      "Epoch 367/500\n",
      "33600/33600 [==============================] - 109s 3ms/step - loss: 0.0400 - accuracy: 0.9934 - val_loss: 0.1066 - val_accuracy: 0.9949\n",
      "Epoch 368/500\n",
      "33600/33600 [==============================] - 108s 3ms/step - loss: 0.0426 - accuracy: 0.9934 - val_loss: 0.0810 - val_accuracy: 0.9932\n",
      "Epoch 369/500\n",
      "33600/33600 [==============================] - 110s 3ms/step - loss: 0.0407 - accuracy: 0.9943 - val_loss: 0.1318 - val_accuracy: 0.9935\n",
      "Epoch 370/500\n",
      "33600/33600 [==============================] - 107s 3ms/step - loss: 0.0454 - accuracy: 0.9947 - val_loss: 0.0981 - val_accuracy: 0.9943\n",
      "Epoch 371/500\n",
      "33600/33600 [==============================] - 108s 3ms/step - loss: 0.0303 - accuracy: 0.9947 - val_loss: 0.1969 - val_accuracy: 0.9939\n",
      "Epoch 372/500\n",
      "33600/33600 [==============================] - 108s 3ms/step - loss: 0.0438 - accuracy: 0.9943 - val_loss: 0.0747 - val_accuracy: 0.9931\n",
      "Epoch 373/500\n",
      "33600/33600 [==============================] - 110s 3ms/step - loss: 0.0456 - accuracy: 0.9950 - val_loss: 0.0858 - val_accuracy: 0.9938\n",
      "Epoch 374/500\n",
      "33600/33600 [==============================] - 112s 3ms/step - loss: 0.0412 - accuracy: 0.9941 - val_loss: 0.0951 - val_accuracy: 0.9907\n",
      "Epoch 375/500\n",
      "33600/33600 [==============================] - 106s 3ms/step - loss: 0.0385 - accuracy: 0.9947 - val_loss: 0.0607 - val_accuracy: 0.9945\n",
      "Epoch 376/500\n",
      "33600/33600 [==============================] - 105s 3ms/step - loss: 0.0393 - accuracy: 0.9944 - val_loss: 0.0711 - val_accuracy: 0.9913\n",
      "Epoch 377/500\n",
      "33600/33600 [==============================] - 106s 3ms/step - loss: 0.0411 - accuracy: 0.9944 - val_loss: 0.1495 - val_accuracy: 0.9932\n",
      "Epoch 378/500\n",
      "33600/33600 [==============================] - 106s 3ms/step - loss: 0.0349 - accuracy: 0.9949 - val_loss: 0.0820 - val_accuracy: 0.9942\n",
      "Epoch 379/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33600/33600 [==============================] - 106s 3ms/step - loss: 0.0433 - accuracy: 0.9957 - val_loss: 0.1457 - val_accuracy: 0.9925\n",
      "Epoch 380/500\n",
      "33600/33600 [==============================] - 108s 3ms/step - loss: 0.0431 - accuracy: 0.9944 - val_loss: 0.0743 - val_accuracy: 0.9908\n",
      "Epoch 381/500\n",
      "33600/33600 [==============================] - 105s 3ms/step - loss: 0.0395 - accuracy: 0.9944 - val_loss: 0.0585 - val_accuracy: 0.9925\n",
      "Epoch 382/500\n",
      "33600/33600 [==============================] - 108s 3ms/step - loss: 0.0503 - accuracy: 0.9935 - val_loss: 0.0989 - val_accuracy: 0.9933\n",
      "Epoch 383/500\n",
      "33600/33600 [==============================] - 107s 3ms/step - loss: 0.0451 - accuracy: 0.9939 - val_loss: 0.0775 - val_accuracy: 0.9935\n",
      "Epoch 384/500\n",
      "33600/33600 [==============================] - 107s 3ms/step - loss: 0.0418 - accuracy: 0.9945 - val_loss: 0.0947 - val_accuracy: 0.9936\n",
      "Epoch 385/500\n",
      "33600/33600 [==============================] - 108s 3ms/step - loss: 0.0600 - accuracy: 0.9934 - val_loss: 0.1643 - val_accuracy: 0.9938\n",
      "Epoch 386/500\n",
      "33600/33600 [==============================] - 106s 3ms/step - loss: 0.0342 - accuracy: 0.9945 - val_loss: 0.1755 - val_accuracy: 0.9940\n",
      "Epoch 387/500\n",
      "33600/33600 [==============================] - 105s 3ms/step - loss: 0.0403 - accuracy: 0.9946 - val_loss: 0.0898 - val_accuracy: 0.9910\n",
      "Epoch 388/500\n",
      "33600/33600 [==============================] - 109s 3ms/step - loss: 0.0506 - accuracy: 0.9940 - val_loss: 0.1396 - val_accuracy: 0.9929\n",
      "Epoch 389/500\n",
      "33600/33600 [==============================] - 108s 3ms/step - loss: 0.0408 - accuracy: 0.9945 - val_loss: 0.2061 - val_accuracy: 0.9932\n",
      "Epoch 390/500\n",
      "33600/33600 [==============================] - 104s 3ms/step - loss: 0.0385 - accuracy: 0.9942 - val_loss: 0.1229 - val_accuracy: 0.9929\n",
      "Epoch 391/500\n",
      "33600/33600 [==============================] - 108s 3ms/step - loss: 0.0457 - accuracy: 0.9935 - val_loss: 0.1959 - val_accuracy: 0.9933\n",
      "Epoch 392/500\n",
      "33600/33600 [==============================] - 108s 3ms/step - loss: 0.0568 - accuracy: 0.9919 - val_loss: 0.1721 - val_accuracy: 0.9925\n",
      "Epoch 393/500\n",
      "33600/33600 [==============================] - 111s 3ms/step - loss: 0.0595 - accuracy: 0.9925 - val_loss: 0.1451 - val_accuracy: 0.9933\n",
      "Epoch 394/500\n",
      "33600/33600 [==============================] - 106s 3ms/step - loss: 0.0473 - accuracy: 0.9945 - val_loss: 0.0673 - val_accuracy: 0.9932\n",
      "Epoch 395/500\n",
      "33600/33600 [==============================] - 106s 3ms/step - loss: 0.0405 - accuracy: 0.9941 - val_loss: 0.0754 - val_accuracy: 0.9912\n",
      "Epoch 396/500\n",
      "33600/33600 [==============================] - 104s 3ms/step - loss: 0.0515 - accuracy: 0.9930 - val_loss: 0.1158 - val_accuracy: 0.9940\n",
      "Epoch 397/500\n",
      "33600/33600 [==============================] - 105s 3ms/step - loss: 0.0484 - accuracy: 0.9948 - val_loss: 0.1947 - val_accuracy: 0.9924\n",
      "Epoch 398/500\n",
      "33600/33600 [==============================] - 105s 3ms/step - loss: 0.0536 - accuracy: 0.9939 - val_loss: 0.1233 - val_accuracy: 0.9936\n",
      "Epoch 399/500\n",
      "33600/33600 [==============================] - 106s 3ms/step - loss: 0.0355 - accuracy: 0.9950 - val_loss: 0.0808 - val_accuracy: 0.9937\n",
      "Epoch 400/500\n",
      "33600/33600 [==============================] - 105s 3ms/step - loss: 0.0433 - accuracy: 0.9941 - val_loss: 0.0849 - val_accuracy: 0.9919\n",
      "Epoch 401/500\n",
      "33600/33600 [==============================] - 106s 3ms/step - loss: 0.0462 - accuracy: 0.9943 - val_loss: 0.0787 - val_accuracy: 0.9910\n",
      "Epoch 402/500\n",
      "33600/33600 [==============================] - 106s 3ms/step - loss: 0.0489 - accuracy: 0.9935 - val_loss: 0.0752 - val_accuracy: 0.9918\n",
      "Epoch 403/500\n",
      "33600/33600 [==============================] - 105s 3ms/step - loss: 0.0414 - accuracy: 0.9936 - val_loss: 0.0917 - val_accuracy: 0.9920\n",
      "Epoch 404/500\n",
      "33600/33600 [==============================] - 104s 3ms/step - loss: 0.0487 - accuracy: 0.9939 - val_loss: 0.0732 - val_accuracy: 0.9923\n",
      "Epoch 405/500\n",
      "33600/33600 [==============================] - 105s 3ms/step - loss: 0.0709 - accuracy: 0.9926 - val_loss: 0.0612 - val_accuracy: 0.9920\n",
      "Epoch 406/500\n",
      "33600/33600 [==============================] - 108s 3ms/step - loss: 0.0439 - accuracy: 0.9938 - val_loss: 0.0584 - val_accuracy: 0.9921\n",
      "Epoch 407/500\n",
      "33600/33600 [==============================] - 103s 3ms/step - loss: 0.0356 - accuracy: 0.9946 - val_loss: 0.0569 - val_accuracy: 0.9923\n",
      "Epoch 408/500\n",
      "33600/33600 [==============================] - 104s 3ms/step - loss: 0.0601 - accuracy: 0.9946 - val_loss: 0.1028 - val_accuracy: 0.9923\n",
      "Epoch 409/500\n",
      "33600/33600 [==============================] - 103s 3ms/step - loss: 0.0543 - accuracy: 0.9945 - val_loss: 0.2071 - val_accuracy: 0.9930\n",
      "Epoch 410/500\n",
      "33600/33600 [==============================] - 104s 3ms/step - loss: 0.0451 - accuracy: 0.9945 - val_loss: 0.0673 - val_accuracy: 0.9913\n",
      "Epoch 411/500\n",
      "33600/33600 [==============================] - 105s 3ms/step - loss: 0.0529 - accuracy: 0.9936 - val_loss: 0.0784 - val_accuracy: 0.9929\n",
      "Epoch 412/500\n",
      "33600/33600 [==============================] - 104s 3ms/step - loss: 0.0523 - accuracy: 0.9929 - val_loss: 0.0910 - val_accuracy: 0.9924\n",
      "Epoch 413/500\n",
      "33600/33600 [==============================] - 117s 3ms/step - loss: 0.0482 - accuracy: 0.9946 - val_loss: 0.0733 - val_accuracy: 0.9911\n",
      "Epoch 414/500\n",
      "33600/33600 [==============================] - 118s 4ms/step - loss: 0.0578 - accuracy: 0.9928 - val_loss: 0.1841 - val_accuracy: 0.9931\n",
      "Epoch 415/500\n",
      "33600/33600 [==============================] - 126s 4ms/step - loss: 0.0465 - accuracy: 0.9957 - val_loss: 0.0925 - val_accuracy: 0.9901\n",
      "Epoch 416/500\n",
      "33600/33600 [==============================] - 115s 3ms/step - loss: 0.0523 - accuracy: 0.9917 - val_loss: 0.1151 - val_accuracy: 0.9918\n",
      "Epoch 417/500\n",
      "33600/33600 [==============================] - 108s 3ms/step - loss: 0.0503 - accuracy: 0.9941 - val_loss: 0.0763 - val_accuracy: 0.9935\n",
      "Epoch 418/500\n",
      "33600/33600 [==============================] - 119s 4ms/step - loss: 0.0366 - accuracy: 0.9940 - val_loss: 0.1073 - val_accuracy: 0.9929\n",
      "Epoch 419/500\n",
      "33600/33600 [==============================] - 116s 3ms/step - loss: 0.0533 - accuracy: 0.9945 - val_loss: 0.1152 - val_accuracy: 0.9932\n",
      "Epoch 420/500\n",
      "33600/33600 [==============================] - 110s 3ms/step - loss: 0.0315 - accuracy: 0.9954 - val_loss: 0.2128 - val_accuracy: 0.9931\n",
      "Epoch 421/500\n",
      "33600/33600 [==============================] - 135s 4ms/step - loss: 0.0331 - accuracy: 0.9956 - val_loss: 0.0917 - val_accuracy: 0.9920\n",
      "Epoch 422/500\n",
      "33600/33600 [==============================] - 123s 4ms/step - loss: 0.0721 - accuracy: 0.9932 - val_loss: 0.0929 - val_accuracy: 0.9930\n",
      "Epoch 423/500\n",
      "33600/33600 [==============================] - 114s 3ms/step - loss: 0.0492 - accuracy: 0.9918 - val_loss: 0.0516 - val_accuracy: 0.9908\n",
      "Epoch 424/500\n",
      "33600/33600 [==============================] - 114s 3ms/step - loss: 0.0602 - accuracy: 0.9931 - val_loss: 0.0639 - val_accuracy: 0.9904\n",
      "Epoch 425/500\n",
      "33600/33600 [==============================] - 118s 4ms/step - loss: 0.0512 - accuracy: 0.9923 - val_loss: 0.0891 - val_accuracy: 0.9917\n",
      "Epoch 426/500\n",
      "33600/33600 [==============================] - 111s 3ms/step - loss: 0.0442 - accuracy: 0.9936 - val_loss: 0.1400 - val_accuracy: 0.9938\n",
      "Epoch 427/500\n",
      "33600/33600 [==============================] - 108s 3ms/step - loss: 0.0439 - accuracy: 0.9947 - val_loss: 0.0662 - val_accuracy: 0.9925\n",
      "Epoch 428/500\n",
      "33600/33600 [==============================] - 108s 3ms/step - loss: 0.0617 - accuracy: 0.9940 - val_loss: 0.1436 - val_accuracy: 0.9910\n",
      "Epoch 429/500\n",
      "33600/33600 [==============================] - 111s 3ms/step - loss: 0.0565 - accuracy: 0.9928 - val_loss: 0.0714 - val_accuracy: 0.9932\n",
      "Epoch 430/500\n",
      "33600/33600 [==============================] - 120s 4ms/step - loss: 0.0429 - accuracy: 0.9937 - val_loss: 0.0978 - val_accuracy: 0.9899\n",
      "Epoch 431/500\n",
      "33600/33600 [==============================] - 109s 3ms/step - loss: 0.0381 - accuracy: 0.9935 - val_loss: 0.0779 - val_accuracy: 0.9900\n",
      "Epoch 432/500\n",
      "33600/33600 [==============================] - 108s 3ms/step - loss: 0.0553 - accuracy: 0.9938 - val_loss: 0.1014 - val_accuracy: 0.9918\n",
      "Epoch 433/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33600/33600 [==============================] - 111s 3ms/step - loss: 0.0360 - accuracy: 0.9934 - val_loss: 0.0758 - val_accuracy: 0.9900\n",
      "Epoch 434/500\n",
      "33600/33600 [==============================] - 120s 4ms/step - loss: 0.0627 - accuracy: 0.9932 - val_loss: 0.0731 - val_accuracy: 0.9921\n",
      "Epoch 435/500\n",
      "33600/33600 [==============================] - 116s 3ms/step - loss: 0.0533 - accuracy: 0.9948 - val_loss: 0.0616 - val_accuracy: 0.9902\n",
      "Epoch 436/500\n",
      "33600/33600 [==============================] - 110s 3ms/step - loss: 0.0668 - accuracy: 0.9930 - val_loss: 0.0738 - val_accuracy: 0.9932\n",
      "Epoch 437/500\n",
      "33600/33600 [==============================] - 109s 3ms/step - loss: 0.0454 - accuracy: 0.9945 - val_loss: 0.0653 - val_accuracy: 0.9917\n",
      "Epoch 438/500\n",
      "33600/33600 [==============================] - 110s 3ms/step - loss: 0.0453 - accuracy: 0.9941 - val_loss: 0.1089 - val_accuracy: 0.9940\n",
      "Epoch 439/500\n",
      "33600/33600 [==============================] - 107s 3ms/step - loss: 0.0539 - accuracy: 0.9925 - val_loss: 0.0994 - val_accuracy: 0.9907\n",
      "Epoch 440/500\n",
      "33600/33600 [==============================] - 108s 3ms/step - loss: 0.0450 - accuracy: 0.9935 - val_loss: 0.0660 - val_accuracy: 0.9930\n",
      "Epoch 441/500\n",
      "33600/33600 [==============================] - 109s 3ms/step - loss: 0.0404 - accuracy: 0.9954 - val_loss: 0.0943 - val_accuracy: 0.9919\n",
      "Epoch 442/500\n",
      "33600/33600 [==============================] - 111s 3ms/step - loss: 0.0525 - accuracy: 0.9927 - val_loss: 0.1058 - val_accuracy: 0.9920\n",
      "Epoch 443/500\n",
      "33600/33600 [==============================] - 107s 3ms/step - loss: 0.0518 - accuracy: 0.9925 - val_loss: 0.0790 - val_accuracy: 0.9815\n",
      "Epoch 444/500\n",
      "33600/33600 [==============================] - 106s 3ms/step - loss: 0.0618 - accuracy: 0.9913 - val_loss: 0.0633 - val_accuracy: 0.9904\n",
      "Epoch 445/500\n",
      "33600/33600 [==============================] - 106s 3ms/step - loss: 0.0443 - accuracy: 0.9935 - val_loss: 0.2497 - val_accuracy: 0.9925\n",
      "Epoch 446/500\n",
      "33600/33600 [==============================] - 109s 3ms/step - loss: 0.0477 - accuracy: 0.9928 - val_loss: 0.1631 - val_accuracy: 0.9932\n",
      "Epoch 447/500\n",
      "33600/33600 [==============================] - 107s 3ms/step - loss: 0.0498 - accuracy: 0.9920 - val_loss: 0.0668 - val_accuracy: 0.9899\n",
      "Epoch 448/500\n",
      "33600/33600 [==============================] - 107s 3ms/step - loss: 0.0559 - accuracy: 0.9930 - val_loss: 0.1030 - val_accuracy: 0.9925\n",
      "Epoch 449/500\n",
      "33600/33600 [==============================] - 107s 3ms/step - loss: 0.0453 - accuracy: 0.9936 - val_loss: 0.1124 - val_accuracy: 0.9927\n",
      "Epoch 450/500\n",
      "33600/33600 [==============================] - 106s 3ms/step - loss: 0.0568 - accuracy: 0.9919 - val_loss: 0.1684 - val_accuracy: 0.9911\n",
      "Epoch 451/500\n",
      "33600/33600 [==============================] - 108s 3ms/step - loss: 0.0424 - accuracy: 0.9924 - val_loss: 0.1185 - val_accuracy: 0.9912\n",
      "Epoch 452/500\n",
      "33600/33600 [==============================] - 106s 3ms/step - loss: 0.0674 - accuracy: 0.9927 - val_loss: 0.2372 - val_accuracy: 0.9926\n",
      "Epoch 453/500\n",
      "33600/33600 [==============================] - 106s 3ms/step - loss: 0.0508 - accuracy: 0.9936 - val_loss: 0.1778 - val_accuracy: 0.9923\n",
      "Epoch 454/500\n",
      "33600/33600 [==============================] - 110s 3ms/step - loss: 0.0601 - accuracy: 0.9931 - val_loss: 0.0774 - val_accuracy: 0.9910\n",
      "Epoch 455/500\n",
      "33600/33600 [==============================] - 109s 3ms/step - loss: 0.0655 - accuracy: 0.9919 - val_loss: 0.1432 - val_accuracy: 0.9926\n",
      "Epoch 456/500\n",
      "33600/33600 [==============================] - 110s 3ms/step - loss: 0.0517 - accuracy: 0.9926 - val_loss: 0.0919 - val_accuracy: 0.9920\n",
      "Epoch 457/500\n",
      "33600/33600 [==============================] - 109s 3ms/step - loss: 0.0600 - accuracy: 0.9930 - val_loss: 0.1446 - val_accuracy: 0.9924\n",
      "Epoch 458/500\n",
      "33600/33600 [==============================] - 110s 3ms/step - loss: 0.0566 - accuracy: 0.9945 - val_loss: 0.0592 - val_accuracy: 0.9917\n",
      "Epoch 459/500\n",
      "33600/33600 [==============================] - 113s 3ms/step - loss: 0.0506 - accuracy: 0.9935 - val_loss: 0.0859 - val_accuracy: 0.9937\n",
      "Epoch 460/500\n",
      "33600/33600 [==============================] - 108s 3ms/step - loss: 0.0478 - accuracy: 0.9919 - val_loss: 0.1749 - val_accuracy: 0.9926\n",
      "Epoch 461/500\n",
      "33600/33600 [==============================] - 108s 3ms/step - loss: 0.0449 - accuracy: 0.9930 - val_loss: 0.0665 - val_accuracy: 0.9929\n",
      "Epoch 462/500\n",
      "33600/33600 [==============================] - 110s 3ms/step - loss: 0.0902 - accuracy: 0.9924 - val_loss: 0.0652 - val_accuracy: 0.9927\n",
      "Epoch 463/500\n",
      "33600/33600 [==============================] - 110s 3ms/step - loss: 0.0545 - accuracy: 0.9932 - val_loss: 0.1147 - val_accuracy: 0.9938\n",
      "Epoch 464/500\n",
      "33600/33600 [==============================] - 124s 4ms/step - loss: 0.0441 - accuracy: 0.9934 - val_loss: 0.0608 - val_accuracy: 0.9910\n",
      "Epoch 465/500\n",
      "33600/33600 [==============================] - 109s 3ms/step - loss: 0.0473 - accuracy: 0.9938 - val_loss: 0.1164 - val_accuracy: 0.9911\n",
      "Epoch 466/500\n",
      "33600/33600 [==============================] - 106s 3ms/step - loss: 0.0567 - accuracy: 0.9937 - val_loss: 0.0798 - val_accuracy: 0.9919\n",
      "Epoch 467/500\n",
      "33600/33600 [==============================] - 109s 3ms/step - loss: 0.0546 - accuracy: 0.9927 - val_loss: 0.0931 - val_accuracy: 0.9921\n",
      "Epoch 468/500\n",
      "33600/33600 [==============================] - 108s 3ms/step - loss: 0.0444 - accuracy: 0.9933 - val_loss: 0.1084 - val_accuracy: 0.9910\n",
      "Epoch 469/500\n",
      "33600/33600 [==============================] - 106s 3ms/step - loss: 0.0550 - accuracy: 0.9922 - val_loss: 0.0728 - val_accuracy: 0.9923\n",
      "Epoch 470/500\n",
      "33600/33600 [==============================] - 116s 3ms/step - loss: 0.0501 - accuracy: 0.9921 - val_loss: 0.1077 - val_accuracy: 0.9930\n",
      "Epoch 471/500\n",
      "33600/33600 [==============================] - 112s 3ms/step - loss: 0.0513 - accuracy: 0.9922 - val_loss: 0.0641 - val_accuracy: 0.9888\n",
      "Epoch 472/500\n",
      "33600/33600 [==============================] - 108s 3ms/step - loss: 0.0558 - accuracy: 0.9934 - val_loss: 0.0978 - val_accuracy: 0.9924\n",
      "Epoch 473/500\n",
      "33600/33600 [==============================] - 108s 3ms/step - loss: 0.0665 - accuracy: 0.9929 - val_loss: 0.0759 - val_accuracy: 0.9906\n",
      "Epoch 474/500\n",
      "33600/33600 [==============================] - 110s 3ms/step - loss: 0.0395 - accuracy: 0.9931 - val_loss: 0.1120 - val_accuracy: 0.9926\n",
      "Epoch 475/500\n",
      "33600/33600 [==============================] - 106s 3ms/step - loss: 0.0654 - accuracy: 0.9909 - val_loss: 0.1317 - val_accuracy: 0.9931\n",
      "Epoch 476/500\n",
      "33600/33600 [==============================] - 109s 3ms/step - loss: 0.0505 - accuracy: 0.9919 - val_loss: 0.0996 - val_accuracy: 0.9933\n",
      "Epoch 477/500\n",
      "33600/33600 [==============================] - 109s 3ms/step - loss: 0.0366 - accuracy: 0.9940 - val_loss: 0.1134 - val_accuracy: 0.9939\n",
      "Epoch 478/500\n",
      "33600/33600 [==============================] - 109s 3ms/step - loss: 0.0505 - accuracy: 0.9937 - val_loss: 0.1445 - val_accuracy: 0.9905\n",
      "Epoch 479/500\n",
      "33600/33600 [==============================] - 112s 3ms/step - loss: 0.0676 - accuracy: 0.9923 - val_loss: 0.0777 - val_accuracy: 0.9895\n",
      "Epoch 480/500\n",
      "33600/33600 [==============================] - 111s 3ms/step - loss: 0.0551 - accuracy: 0.9920 - val_loss: 0.0757 - val_accuracy: 0.9908\n",
      "Epoch 481/500\n",
      "33600/33600 [==============================] - 108s 3ms/step - loss: 0.0668 - accuracy: 0.9927 - val_loss: 0.1091 - val_accuracy: 0.9914\n",
      "Epoch 482/500\n",
      "33600/33600 [==============================] - 107s 3ms/step - loss: 0.0397 - accuracy: 0.9940 - val_loss: 0.0600 - val_accuracy: 0.9917\n",
      "Epoch 483/500\n",
      "33600/33600 [==============================] - 106s 3ms/step - loss: 0.0611 - accuracy: 0.9922 - val_loss: 0.0767 - val_accuracy: 0.9836\n",
      "Epoch 484/500\n",
      "33600/33600 [==============================] - 113s 3ms/step - loss: 0.0636 - accuracy: 0.9928 - val_loss: 0.0737 - val_accuracy: 0.9899\n",
      "Epoch 485/500\n",
      "33600/33600 [==============================] - 107s 3ms/step - loss: 0.0386 - accuracy: 0.9937 - val_loss: 0.1077 - val_accuracy: 0.9881\n",
      "Epoch 486/500\n",
      "33600/33600 [==============================] - 108s 3ms/step - loss: 0.0851 - accuracy: 0.9913 - val_loss: 0.0712 - val_accuracy: 0.9906\n",
      "Epoch 487/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33600/33600 [==============================] - 108s 3ms/step - loss: 0.0434 - accuracy: 0.9941 - val_loss: 0.1347 - val_accuracy: 0.9914\n",
      "Epoch 488/500\n",
      "33600/33600 [==============================] - 108s 3ms/step - loss: 0.0588 - accuracy: 0.9915 - val_loss: 0.1828 - val_accuracy: 0.9908\n",
      "Epoch 489/500\n",
      "33600/33600 [==============================] - 110s 3ms/step - loss: 0.0462 - accuracy: 0.9936 - val_loss: 0.2082 - val_accuracy: 0.9940\n",
      "Epoch 490/500\n",
      "33600/33600 [==============================] - 109s 3ms/step - loss: 0.0568 - accuracy: 0.9931 - val_loss: 0.2294 - val_accuracy: 0.9932\n",
      "Epoch 491/500\n",
      "33600/33600 [==============================] - 111s 3ms/step - loss: 0.0665 - accuracy: 0.9919 - val_loss: 0.1350 - val_accuracy: 0.9917\n",
      "Epoch 492/500\n",
      "33600/33600 [==============================] - 110s 3ms/step - loss: 0.0483 - accuracy: 0.9924 - val_loss: 0.1669 - val_accuracy: 0.9923\n",
      "Epoch 493/500\n",
      "33600/33600 [==============================] - 106s 3ms/step - loss: 0.0620 - accuracy: 0.9929 - val_loss: 0.0993 - val_accuracy: 0.9889\n",
      "Epoch 494/500\n",
      "33600/33600 [==============================] - 108s 3ms/step - loss: 0.0676 - accuracy: 0.9915 - val_loss: 0.0924 - val_accuracy: 0.9926\n",
      "Epoch 495/500\n",
      "33600/33600 [==============================] - 112s 3ms/step - loss: 0.0549 - accuracy: 0.9924 - val_loss: 0.1047 - val_accuracy: 0.9898\n",
      "Epoch 496/500\n",
      "33600/33600 [==============================] - 106s 3ms/step - loss: 0.0563 - accuracy: 0.9905 - val_loss: 0.1030 - val_accuracy: 0.9917\n",
      "Epoch 497/500\n",
      "33600/33600 [==============================] - 107s 3ms/step - loss: 0.0581 - accuracy: 0.9913 - val_loss: 0.0834 - val_accuracy: 0.9925\n",
      "Epoch 498/500\n",
      "33600/33600 [==============================] - 111s 3ms/step - loss: 0.0582 - accuracy: 0.9927 - val_loss: 0.1026 - val_accuracy: 0.9895\n",
      "Epoch 499/500\n",
      "33600/33600 [==============================] - 106s 3ms/step - loss: 0.0625 - accuracy: 0.9917 - val_loss: 0.0938 - val_accuracy: 0.9915\n",
      "Epoch 500/500\n",
      "33600/33600 [==============================] - 106s 3ms/step - loss: 0.0748 - accuracy: 0.9922 - val_loss: 0.1712 - val_accuracy: 0.9913\n",
      "8400/8400 [==============================] - 11s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.1712227933988474, 0.9913095235824585]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=create_model()\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(xtrain, ytrain, batch_size=256, epochs=500, verbose=1, validation_data=(xtest, ytest))\n",
    "model.evaluate(xtest, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'val_accuracy', 'loss', 'accuracy'])\n"
     ]
    }
   ],
   "source": [
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Singleton array 2 cannot be considered a valid collection.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-117eb7138313>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mytest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mytest\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Decode labels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mmat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mytest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Confusion matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m# Plot Confusion matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[1;34m(y_true, y_pred, labels, sample_weight)\u001b[0m\n\u001b[0;32m    251\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m     \"\"\"\n\u001b[1;32m--> 253\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    254\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"multiclass\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%s is not supported\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0marray\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m     \"\"\"\n\u001b[1;32m---> 71\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    199\u001b[0m     \"\"\"\n\u001b[0;32m    200\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m     \u001b[0mlengths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m     \u001b[0muniques\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    199\u001b[0m     \"\"\"\n\u001b[0;32m    200\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m     \u001b[0mlengths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m     \u001b[0muniques\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_num_samples\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    144\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m             raise TypeError(\"Singleton array %r cannot be considered\"\n\u001b[1;32m--> 146\u001b[1;33m                             \" a valid collection.\" % x)\n\u001b[0m\u001b[0;32m    147\u001b[0m         \u001b[1;31m# Check that shape is returning an integer or default to len\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m         \u001b[1;31m# Dask dataframes may not return numeric shape[0] value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Singleton array 2 cannot be considered a valid collection."
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10)) # Set Figure\n",
    "\n",
    "pred = model.predict(xtest) # Predict encoded label as 2 => [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
    "\n",
    "pred = np.argmax(pred) # Decode Predicted labels\n",
    "ytest = np.argmax(ytest) # Decode labels\n",
    "\n",
    "mat = confusion_matrix(ytest, pred) # Confusion matrix\n",
    "\n",
    "# Plot Confusion matrix\n",
    "sns.heatmap(mat.T, square=True, annot=True, cbar=False, cmap=plt.cm.Blues)\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.ylabel('True Values');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
